{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Milestone Project 1: Food Vision Big","metadata":{"id":"xNehDsHCFywy"}},{"cell_type":"markdown","source":"## Check GPU\n\nGoogle Colab offers free GPUs,all of them are comaptible for mixed precision training.. however,if you use other GPU not all of them are compatible with mixed precision training.\n\nGoogle Colab offers:\n* A100(compatible)\n* V100(compatible)\n* Tesla T4(compatible)\nKnowing this, in order to use mixed precision training we need access to any one or if we're using our own hardware, our GPU needs a score of 7.0+(see here: https://developer.nvidia.com/cuda/cuda-gpus)\n","metadata":{"id":"qrZadKnZIfnk"}},{"cell_type":"code","source":"!nvidia-smi -L","metadata":{"id":"7PkrvBPrLrVP","outputId":"9c5bdb69-3214-4647-b0d5-a321e1cb97e0","execution":{"iopub.status.busy":"2023-07-21T05:34:00.360598Z","iopub.execute_input":"2023-07-21T05:34:00.360980Z","iopub.status.idle":"2023-07-21T05:34:01.475746Z","shell.execute_reply.started":"2023-07-21T05:34:00.360952Z","shell.execute_reply":"2023-07-21T05:34:01.474192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get helper functions\n","metadata":{"id":"Q_CsRmU3Nee-"}},{"cell_type":"code","source":"# Download helper functions\n!wget https://raw.githubusercontent.com//mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py","metadata":{"id":"B0Nd7V37N6Y0","outputId":"58501d95-9955-4f5c-dc21-a555cb8dc58f","execution":{"iopub.status.busy":"2023-07-21T05:35:06.974780Z","iopub.execute_input":"2023-07-21T05:35:06.975179Z","iopub.status.idle":"2023-07-21T05:35:08.182633Z","shell.execute_reply.started":"2023-07-21T05:35:06.975146Z","shell.execute_reply":"2023-07-21T05:35:08.181373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import series of helper functions for the notebook\nfrom helper_functions import create_tensorboard_callback, plot_loss_curves, compare_historys","metadata":{"id":"CriLCZ4HOZU0","execution":{"iopub.status.busy":"2023-07-21T05:35:08.184818Z","iopub.execute_input":"2023-07-21T05:35:08.185274Z","iopub.status.idle":"2023-07-21T05:35:17.867531Z","shell.execute_reply.started":"2023-07-21T05:35:08.185238Z","shell.execute_reply":"2023-07-21T05:35:17.866298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Use TensorFlow Datasets to Download Data","metadata":{"id":"ei2c9RQ2On2g"}},{"cell_type":"code","source":"# Get TensorFlow Datasets\nimport tensorflow_datasets as tfds","metadata":{"id":"EpnSsB3mPUWV","execution":{"iopub.status.busy":"2023-07-21T05:35:17.869620Z","iopub.execute_input":"2023-07-21T05:35:17.870799Z","iopub.status.idle":"2023-07-21T05:35:19.582133Z","shell.execute_reply.started":"2023-07-21T05:35:17.870755Z","shell.execute_reply":"2023-07-21T05:35:19.581070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# list all available datasets\ndatasets_list = tfds.list_builders() # Get all available datasets in TFDS\nprint(\"food101\" in datasets_list) # is our target datset in TFDS","metadata":{"id":"DNpl_3KzQFv_","outputId":"59872041-20de-45eb-9588-8449fefe7860","execution":{"iopub.status.busy":"2023-07-21T05:35:19.583577Z","iopub.execute_input":"2023-07-21T05:35:19.583966Z","iopub.status.idle":"2023-07-21T05:35:21.258953Z","shell.execute_reply.started":"2023-07-21T05:35:19.583933Z","shell.execute_reply":"2023-07-21T05:35:21.257971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load in the data(takes 5-6 minutes in Colab)\n(train_data, test_data), ds_info = tfds.load(name=\"food101\",\n                                             split=[\"train\", \"validation\"],\n                                             shuffle_files=False,\n                                             as_supervised=True, #Data get returned in tuple format(data, label)\n                                             with_info= True)","metadata":{"id":"1PgNc8hxQnwe","execution":{"iopub.status.busy":"2023-07-21T05:35:21.260697Z","iopub.execute_input":"2023-07-21T05:35:21.260971Z","iopub.status.idle":"2023-07-21T05:45:59.736376Z","shell.execute_reply.started":"2023-07-21T05:35:21.260944Z","shell.execute_reply":"2023-07-21T05:45:59.733429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploting the Food101 data from  TensorFlow Datasets\nTo become one with our data, we want to find:\n* Class names\n* The shape of our input data(image tensors)\n* The datatype of our input data\n* What the labels look like(e.g. are they one-hot encoded or they are label encoded)\n* Do the labels match up with the class names?","metadata":{"id":"Tab62X9mW_3P"}},{"cell_type":"code","source":"ds_info","metadata":{"execution":{"iopub.status.busy":"2023-07-19T09:15:28.143647Z","iopub.execute_input":"2023-07-19T09:15:28.144377Z","iopub.status.idle":"2023-07-19T09:15:28.153697Z","shell.execute_reply.started":"2023-07-19T09:15:28.144341Z","shell.execute_reply":"2023-07-19T09:15:28.152726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature of Food101 from TFDS\nds_info.features","metadata":{"id":"nQU4iUZYSxD8","outputId":"c331e6ce-8f3f-4d79-c846-d8118cdd7ee9","execution":{"iopub.status.busy":"2023-07-19T09:15:29.168429Z","iopub.execute_input":"2023-07-19T09:15:29.169469Z","iopub.status.idle":"2023-07-19T09:15:29.177931Z","shell.execute_reply.started":"2023-07-19T09:15:29.169424Z","shell.execute_reply":"2023-07-19T09:15:29.176846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the class names\nclass_names = ds_info.features[\"label\"].names\nclass_names[:10]","metadata":{"id":"oluAo19tWbxm","outputId":"3768265e-40a1-4742-ab07-38d137ad4bc3","execution":{"iopub.status.busy":"2023-07-21T05:45:59.739945Z","iopub.execute_input":"2023-07-21T05:45:59.740330Z","iopub.status.idle":"2023-07-21T05:45:59.750907Z","shell.execute_reply.started":"2023-07-21T05:45:59.740291Z","shell.execute_reply":"2023-07-21T05:45:59.749474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Take one sample of the train data\ntrain_one_sample = train_data.take(1)  # samples are in format (image_tensor, label)","metadata":{"id":"BdIB34oTWxZp","execution":{"iopub.status.busy":"2023-07-19T09:15:30.839872Z","iopub.execute_input":"2023-07-19T09:15:30.840291Z","iopub.status.idle":"2023-07-19T09:15:30.853353Z","shell.execute_reply.started":"2023-07-19T09:15:30.840255Z","shell.execute_reply":"2023-07-19T09:15:30.852285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# What does one sample of our training data look like?\ntrain_one_sample","metadata":{"id":"a3UQom0uX41s","outputId":"581b562b-5da9-4985-e468-811133a69ee2","execution":{"iopub.status.busy":"2023-07-19T09:15:31.550403Z","iopub.execute_input":"2023-07-19T09:15:31.551293Z","iopub.status.idle":"2023-07-19T09:15:31.563208Z","shell.execute_reply.started":"2023-07-19T09:15:31.551248Z","shell.execute_reply":"2023-07-19T09:15:31.561889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Output info about our training sample\nfor image, label in train_one_sample:\n  print(f\"\"\"\n  Image shape: {image.shape}\n  Image datatype : {image.dtype}\n  Target class from Food101(tensor form): {label}\n  Class name (str form): {class_names[label.numpy()]}\n  \"\"\")","metadata":{"id":"zY3Lt_KvYXP4","outputId":"372a6df5-e5e0-4702-bf85-254f835b4b27","execution":{"iopub.status.busy":"2023-07-19T09:15:32.356932Z","iopub.execute_input":"2023-07-19T09:15:32.357774Z","iopub.status.idle":"2023-07-19T09:15:32.989219Z","shell.execute_reply.started":"2023-07-19T09:15:32.357734Z","shell.execute_reply":"2023-07-19T09:15:32.988225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# What does our image tensor from TFDS's Food 101 look like?\nimage","metadata":{"id":"qgf2EuXcZcMY","outputId":"afadaec9-2ff2-4acc-ff62-b4d5423ff7b6","execution":{"iopub.status.busy":"2023-07-19T09:15:33.085136Z","iopub.execute_input":"2023-07-19T09:15:33.085494Z","iopub.status.idle":"2023-07-19T09:15:33.098858Z","shell.execute_reply.started":"2023-07-19T09:15:33.085465Z","shell.execute_reply":"2023-07-19T09:15:33.097644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# What are the min and max values of image tensor?\nimport tensorflow as tf\n\ntf.reduce_min(image), tf.reduce_max(image)","metadata":{"id":"Z5tKIf34ZlPQ","outputId":"ed3f2285-b64a-4d06-a0ca-e9bffdfd576f","execution":{"iopub.status.busy":"2023-07-19T09:15:34.523403Z","iopub.execute_input":"2023-07-19T09:15:34.524645Z","iopub.status.idle":"2023-07-19T09:15:34.567347Z","shell.execute_reply.started":"2023-07-19T09:15:34.524600Z","shell.execute_reply":"2023-07-19T09:15:34.566196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot an image from TensorFlow Datasets","metadata":{"id":"csGC8jpsZ7B9"}},{"cell_type":"code","source":"# Plot an image tensor\nimport matplotlib.pyplot as plt\nplt.imshow(image)\nplt.title(class_names[label.numpy()])\nplt.axis(False);","metadata":{"id":"WU2iP1WIaQB9","outputId":"3ec348e4-6069-4df3-e18d-3ea04e8cc252","execution":{"iopub.status.busy":"2023-07-19T09:15:37.214673Z","iopub.execute_input":"2023-07-19T09:15:37.215066Z","iopub.status.idle":"2023-07-19T09:15:37.680387Z","shell.execute_reply.started":"2023-07-19T09:15:37.215034Z","shell.execute_reply":"2023-07-19T09:15:37.679422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create preprocessing functions for our data\nNeural networks perform best when data is in a certain way (e.g. batched, normalized, etc.)\n\nHowever, not all data(including data from TensorFlow Datasets) comes like this.\n\nSo, in order to get it ready for a neural network, you'll often have to write preprocessing functions and map it to our data.\n\nWhat we know about our data:\n* In `uint8` datatype\n* Comprised of all different size tensors (different sized images)\n* Not scaled (the pixel values are between 0 and 255)\n\nWhat we know model like:\n* Data in `float32` dtype (or for mixed precision `float16` and `float32`)\n* For batches, TensorFlow likes all of the tensors within a batch to be of the same size\n* Scaled (values between 0 & 1 ) also called normalized tensors generally perform better\n\nWith these points in mind, we've got a few things we can tackle with a preprocessing function.\n\nSince, we're going to be using an EfficientNetBX pretrained model from tf.keras.applications we don't need to rescale our data(these architectures have rescaling built-in)\n\nThis means our fucntions needs to:\n1. Reshape our images to all the same size\n2. Convert the dtype of our image tensors `uint8` to `float32`","metadata":{"id":"H0Mvxpjra2hB"}},{"cell_type":"code","source":"# Make a function for preprocessing images\ndef preprocess_img(image, label, img_shape=224):\n  \"\"\"\n  Converts image datatype from 'uint8' -> 'float32' and reshapes\n  image to [img_shape, img_shape, color_channels]\n  \"\"\"\n  image = tf.image.resize(image, [img_shape, img_shape]) # reshape target image\n  return tf.cast(image, tf.float32), label # return (float32_image, label)\n","metadata":{"id":"ygKFfEafcRQB","execution":{"iopub.status.busy":"2023-07-21T05:45:59.753056Z","iopub.execute_input":"2023-07-21T05:45:59.753837Z","iopub.status.idle":"2023-07-21T05:45:59.775981Z","shell.execute_reply.started":"2023-07-21T05:45:59.753798Z","shell.execute_reply":"2023-07-21T05:45:59.775128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocess a single sample image and check the outputs\npreprocessed_img = preprocess_img(image, label)[0]\nprint(f\"Image before preprocessing:\\n {image[:2]}..., \\nShape: {image.shape}, \\nDatatype: {image.dtype}\")\nprint(f\"Image after preprocessed: \\n{preprocessed_img[:2]}...,\\nShape:{preprocessed_img.shape}, \\nDatatype:{preprocessed_img.dtype} \")","metadata":{"id":"rs-IlI2jhQDT","outputId":"8b882111-162f-4453-fb6a-e2f6e4f88727","execution":{"iopub.status.busy":"2023-07-21T05:45:59.779190Z","iopub.execute_input":"2023-07-21T05:45:59.780894Z","iopub.status.idle":"2023-07-21T05:46:00.516435Z","shell.execute_reply.started":"2023-07-21T05:45:59.780869Z","shell.execute_reply":"2023-07-21T05:46:00.514913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Batch & prepare datasets\n\nWe'now going to make our data input pipeline run really fast\n\nFor more resources on this: https://www.tensorflow.org/guide/data_performance","metadata":{"id":"s5SkY3xRqF-i"}},{"cell_type":"code","source":"# Map preprocessing function to training(and parallelize)\ntrain = train_data.map(map_func=preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n\n# Shuffle train_data and turn it into batches and prefetch it(load it faster)\ntrain = train_data.shuffle(buffer_size=1000).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE) \n\n# Map preprocessing function to test data \ntest = test_data.map(preprocess_img, num_parallel_calls=tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)\n","metadata":{"id":"opc6E-8CrSBl","outputId":"f993a58e-50d7-4ff2-d482-dfc9d614d2c2","execution":{"iopub.status.busy":"2023-07-21T05:46:00.517400Z","iopub.status.idle":"2023-07-21T05:46:00.517995Z","shell.execute_reply.started":"2023-07-21T05:46:00.517735Z","shell.execute_reply":"2023-07-21T05:46:00.517764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, test","metadata":{"id":"k1TjzwZprqyU","execution":{"iopub.status.busy":"2023-07-19T09:15:48.931598Z","iopub.execute_input":"2023-07-19T09:15:48.931983Z","iopub.status.idle":"2023-07-19T09:15:48.939773Z","shell.execute_reply.started":"2023-07-19T09:15:48.931952Z","shell.execute_reply":"2023-07-19T09:15:48.938171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">\"Hey, TensorFlow, map this preprocessing function(`preprocess_img`) across the training dataset, then shuffle a number of elements and then batch them together and finally make sure to prepare new batches(prefetch) whilst the model is looking through(finding patterns) the current batch.\"","metadata":{}},{"cell_type":"markdown","source":"## Create modelling callbacks\n\nWe're going to create some of callbacks to help us while our model trains:\n* TensorBoard callback to log training results (so we can visualize them later if needed to)\n* ModelCheckPoint callback to save our model's progress after feature extraction","metadata":{}},{"cell_type":"code","source":"# Create tensorboard (import from helper_function)\nfrom helper_functions import create_tensorboard_callback\n\n# Create a ModelCheckpoint callback to save a model's progress during training \ncheckpoint_path = \"model_checkpoints/cp.ckpt\"\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n                                                     monitor=\"val_acc\",\n                                                     save_best_only=True,\n                                                     save_weights_only=True,\n                                                     verbose=0)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T10:06:38.570956Z","iopub.execute_input":"2023-07-17T10:06:38.571726Z","iopub.status.idle":"2023-07-17T10:06:38.577757Z","shell.execute_reply.started":"2023-07-17T10:06:38.571692Z","shell.execute_reply":"2023-07-17T10:06:38.576500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setup mixed precision training \n\nFirst and foremost, for a deeper understanding of mixed precision training, checkout training guide: https://www.tensorflow.org/guide/mixed_precision\n\nMixed precision utilizes a combination of float32 and float16 datatypes to speed up model performance","metadata":{}},{"cell_type":"code","source":"# Turn ON mixed precision training \nfrom tensorflow.keras import mixed_precision\n\nmixed_precision.set_global_policy(\"mixed_float16\")#set global data policy to mixed precision ","metadata":{"execution":{"iopub.status.busy":"2023-07-21T05:46:00.520021Z","iopub.status.idle":"2023-07-21T05:46:00.520469Z","shell.execute_reply.started":"2023-07-21T05:46:00.520240Z","shell.execute_reply":"2023-07-21T05:46:00.520262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mixed_precision.global_policy()","metadata":{"execution":{"iopub.status.busy":"2023-07-21T05:46:00.522080Z","iopub.status.idle":"2023-07-21T05:46:00.522536Z","shell.execute_reply.started":"2023-07-21T05:46:00.522302Z","shell.execute_reply":"2023-07-21T05:46:00.522324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build feature extraction model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\n\n# Create base model\ninput_shape = (224,224,3)\nbase_model = tf.keras.applications.EfficientNetB0(include_top=False)\nbase_model.trainable= False\n\n# Create functional model\ninputs= layers.Input(shape=input_shape, name =\"input_layer\")\n# Note: EfficientNetBX models have rescaling built-in but if model do not have it try belo:\n# x= preprocessing.Rescaling(1/255.)(x)\nx = base_model(inputs, training=False) #make sure layers which should be in inference mode only say like that\nx= layers.GlobalAveragePooling2D(name=\"global_pool_layer\")(x)\nx= layers.Dense(len(class_names))(x)\noutputs = layers.Activation(\"softmax\", dtype=tf.float32, name=\"softmax_float32\")(x)\n\nmodel= tf.keras.Model(inputs, outputs)\n\n# Compile the model\nmodel.compile(loss=\"sparse_categorical_crossentropy\",\n             optimizer=\"adam\",\n             metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2023-07-17T10:36:43.853016Z","iopub.execute_input":"2023-07-17T10:36:43.853408Z","iopub.status.idle":"2023-07-17T10:36:47.035602Z","shell.execute_reply.started":"2023-07-17T10:36:43.853379Z","shell.execute_reply":"2023-07-17T10:36:47.034566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-17T10:37:02.295857Z","iopub.execute_input":"2023-07-17T10:37:02.296289Z","iopub.status.idle":"2023-07-17T10:37:02.345583Z","shell.execute_reply.started":"2023-07-17T10:37:02.296248Z","shell.execute_reply":"2023-07-17T10:37:02.344550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Checking layer dtype policies (are we using mixed precision?)","metadata":{}},{"cell_type":"code","source":"# check the dtype_policy attributes of layers in our model\nfor layer in model.layers:\n    print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T10:46:32.708329Z","iopub.execute_input":"2023-07-17T10:46:32.708680Z","iopub.status.idle":"2023-07-17T10:46:32.714711Z","shell.execute_reply.started":"2023-07-17T10:46:32.708653Z","shell.execute_reply":"2023-07-17T10:46:32.713598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the dtype policy for base model\nfor  layer in base_model.layers[:20]:\n    print( layer.name, layer.trainable, layer.dtype, layer.dtype_policy)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T10:46:37.478571Z","iopub.execute_input":"2023-07-17T10:46:37.478939Z","iopub.status.idle":"2023-07-17T10:46:37.486387Z","shell.execute_reply.started":"2023-07-17T10:46:37.478909Z","shell.execute_reply":"2023-07-17T10:46:37.485000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fit the feature extraction model","metadata":{}},{"cell_type":"code","source":"history_101_food_classes_feature_extract = model.fit(train_data,\n                    steps_per_epoch=len(train_data),\n                   validation_steps=int(0.15 * len(test_data)),\n                   validation_data=(test_data),\n                   epochs=3,\n                   callbacks=[create_tensorboard_callback(dir_name=\"training_logs\",\n                                                         experiment_name=\"efficientnetb0_101_classes_all_data_feature_extract\"),\n                             model_checkpoint])","metadata":{"execution":{"iopub.status.busy":"2023-07-17T10:54:12.331224Z","iopub.execute_input":"2023-07-17T10:54:12.331609Z","iopub.status.idle":"2023-07-17T11:03:45.599295Z","shell.execute_reply.started":"2023-07-17T10:54:12.331578Z","shell.execute_reply":"2023-07-17T11:03:45.598224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate model on whole data\nresults_feature_extractor = model.evaluate(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T11:06:08.769972Z","iopub.execute_input":"2023-07-17T11:06:08.770373Z","iopub.status.idle":"2023-07-17T11:07:30.807114Z","shell.execute_reply.started":"2023-07-17T11:06:08.770342Z","shell.execute_reply":"2023-07-17T11:07:30.805955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss_curves(history_101_food_classes_feature_extract)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T11:25:28.408064Z","iopub.execute_input":"2023-07-17T11:25:28.408973Z","iopub.status.idle":"2023-07-17T11:25:29.198838Z","shell.execute_reply.started":"2023-07-17T11:25:28.408940Z","shell.execute_reply":"2023-07-17T11:25:29.197857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fine tuning the model\nFine-tuning the feature extraction model to beat the  [DeepFoodPaper](https://arxiv.org/pdf/1606.05675.pdf)","metadata":{}},{"cell_type":"code","source":"# Download the saved model from Google Storage\n!wget https://storage.googleapis.com/ztm_tf_course/food_vision/07_efficientnetb0_feature_extract_model_mixed_precision.zip ","metadata":{"execution":{"iopub.status.busy":"2023-07-18T06:20:14.607800Z","iopub.execute_input":"2023-07-18T06:20:14.608263Z","iopub.status.idle":"2023-07-18T06:20:16.429916Z","shell.execute_reply.started":"2023-07-18T06:20:14.608217Z","shell.execute_reply":"2023-07-18T06:20:16.428574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from helper_functions import unzip_data\n# Unzip the SavedModel downloaded from Google Stroage\n!mkdir downloaded_gs_model # create new dir to store downloaded feature extraction model\n!unzip 07_efficientnetb0_feature_extract_model_mixed_precision.zip -d downloaded_gs_model     ","metadata":{"execution":{"iopub.status.busy":"2023-07-18T06:20:18.682441Z","iopub.execute_input":"2023-07-18T06:20:18.682862Z","iopub.status.idle":"2023-07-18T06:20:21.020102Z","shell.execute_reply.started":"2023-07-18T06:20:18.682829Z","shell.execute_reply":"2023-07-18T06:20:21.018822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading feature extractor model\nfeature_extractor_model = tf.keras.models.load_model(\"/kaggle/working/downloaded_gs_model/07_efficientnetb0_feature_extract_model_mixed_precision\")","metadata":{"execution":{"iopub.status.busy":"2023-07-18T06:20:22.426091Z","iopub.execute_input":"2023-07-18T06:20:22.426490Z","iopub.status.idle":"2023-07-18T06:20:38.260349Z","shell.execute_reply.started":"2023-07-18T06:20:22.426454Z","shell.execute_reply":"2023-07-18T06:20:38.259171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# How does the loaded model perform? (evaluate it on the test dataset)\nloaded_model_results= feature_extractor_model.evaluate(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-07-18T06:20:42.123962Z","iopub.execute_input":"2023-07-18T06:20:42.124340Z","iopub.status.idle":"2023-07-18T06:22:06.284029Z","shell.execute_reply.started":"2023-07-18T06:20:42.124308Z","shell.execute_reply":"2023-07-18T06:22:06.282887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the summary of downloaded model\nfeature_extractor_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-18T06:23:45.222917Z","iopub.execute_input":"2023-07-18T06:23:45.223323Z","iopub.status.idle":"2023-07-18T06:23:45.280337Z","shell.execute_reply.started":"2023-07-18T06:23:45.223290Z","shell.execute_reply":"2023-07-18T06:23:45.279401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set all of the layers .trainable variable in the loaded model to True (so they're unfrozen)\nfor layer in feature_extractor_model.layers[1].layers:\n    layer.trainable = True","metadata":{"execution":{"iopub.status.busy":"2023-07-18T06:23:49.147000Z","iopub.execute_input":"2023-07-18T06:23:49.147385Z","iopub.status.idle":"2023-07-18T06:23:49.164052Z","shell.execute_reply.started":"2023-07-18T06:23:49.147333Z","shell.execute_reply":"2023-07-18T06:23:49.163127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check all layers are trainable in feature extractor\nfor layer in feature_extractor_model.layers[1].layers:\n    print(layer.name, layer.trainable)","metadata":{"execution":{"iopub.status.busy":"2023-07-18T06:23:50.250777Z","iopub.execute_input":"2023-07-18T06:23:50.251625Z","iopub.status.idle":"2023-07-18T06:23:50.263415Z","shell.execute_reply.started":"2023-07-18T06:23:50.251587Z","shell.execute_reply":"2023-07-18T06:23:50.262187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check to see what dtype_policy of the layers in your loaded model are\nfor layer in feature_extractor_model.layers:\n    print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)","metadata":{"execution":{"iopub.status.busy":"2023-07-18T06:23:54.977800Z","iopub.execute_input":"2023-07-18T06:23:54.978161Z","iopub.status.idle":"2023-07-18T06:23:54.984333Z","shell.execute_reply.started":"2023-07-18T06:23:54.978128Z","shell.execute_reply":"2023-07-18T06:23:54.983376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\n# Monitor the val_loss and stop training if it doesn't improve for 3 epochs\nearly_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3)","metadata":{"execution":{"iopub.status.busy":"2023-07-18T06:23:58.057420Z","iopub.execute_input":"2023-07-18T06:23:58.057789Z","iopub.status.idle":"2023-07-18T06:23:58.062739Z","shell.execute_reply.started":"2023-07-18T06:23:58.057760Z","shell.execute_reply":"2023-07-18T06:23:58.061784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create ModelCheckpoint callback to save best model during fine-tuning\n# Save the best model only\n# Monitor val_loss while training and save the best model (lowest val_loss)\nfine_tune_checkpoint_path = \"fine_tune_checkpoint/cp.ckpt\"\n\nfine_tune_checkpoint= tf.keras.callbacks.ModelCheckpoint(fine_tune_checkpoint_path, \n                                                        save_best_only=True,\n                                                        monitor=\"val_loss\",\n                                                        save_weights_only=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-18T06:24:00.016865Z","iopub.execute_input":"2023-07-18T06:24:00.017227Z","iopub.status.idle":"2023-07-18T06:24:00.023137Z","shell.execute_reply.started":"2023-07-18T06:24:00.017197Z","shell.execute_reply":"2023-07-18T06:24:00.022026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile the model ready for fine-tuning\n# Use the Adam optimizer with a 10x lower than default learning rate\nfeature_extractor_model.compile(loss=\"sparse_categorical_crossentropy\",\n                               optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001),\n                               metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2023-07-18T06:24:01.090451Z","iopub.execute_input":"2023-07-18T06:24:01.090821Z","iopub.status.idle":"2023-07-18T06:24:01.122022Z","shell.execute_reply.started":"2023-07-18T06:24:01.090792Z","shell.execute_reply":"2023-07-18T06:24:01.121061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Start to fine-tune (all layers)..Use 100 epochs as the default..Validate on 15% of the test_data\n# Use the create_tensorboard_callback, ModelCheckpoint and EarlyStopping callbacks you created eaelier\nhistory_fine_tune_model = feature_extractor_model.fit(train_data, \n                                                     epochs=100,\n                                                     steps_per_epoch=len(train_data),\n                                                     validation_data=test_data,\n                                                     validation_steps=int(0.15 * len(test_data)), \n                                                      callbacks=[fine_tune_checkpoint, early_stopping_callback,\n                                                                create_tensorboard_callback(dir_name=\"training_logs\",\n                                                                                           experiment_name=\"fine_tune_101_food_class\")])\n","metadata":{"execution":{"iopub.status.busy":"2023-07-18T06:24:02.975624Z","iopub.execute_input":"2023-07-18T06:24:02.975998Z","iopub.status.idle":"2023-07-18T07:19:09.000768Z","shell.execute_reply.started":"2023-07-18T06:24:02.975968Z","shell.execute_reply":"2023-07-18T07:19:08.999752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_extractor_model.save(\"fine_tuned model.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-07-18T07:32:00.732301Z","iopub.execute_input":"2023-07-18T07:32:00.732702Z","iopub.status.idle":"2023-07-18T07:32:01.277293Z","shell.execute_reply.started":"2023-07-18T07:32:00.732671Z","shell.execute_reply":"2023-07-18T07:32:01.276300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate your fine-tuned model","metadata":{}},{"cell_type":"markdown","source":"> Note: Due to limited RAM space(13GB) reloading the model ","metadata":{}},{"cell_type":"code","source":"# Loading the fine tuned model\nmodel_fine_tuned =  tf.keras.models.load_model(\"/kaggle/input/model-fine-tuned/fine_tuned model.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-07-19T09:16:01.179087Z","iopub.execute_input":"2023-07-19T09:16:01.179624Z","iopub.status.idle":"2023-07-19T09:16:05.850682Z","shell.execute_reply.started":"2023-07-19T09:16:01.179586Z","shell.execute_reply":"2023-07-19T09:16:05.849644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on test data\nresults_fine_tuned_model = model_fine_tuned.evaluate(test) ","metadata":{"execution":{"iopub.status.busy":"2023-07-19T09:16:05.852703Z","iopub.execute_input":"2023-07-19T09:16:05.853047Z","iopub.status.idle":"2023-07-19T09:17:30.294769Z","shell.execute_reply.started":"2023-07-19T09:16:05.853012Z","shell.execute_reply":"2023-07-19T09:17:30.293566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Making prediction with trained model","metadata":{}},{"cell_type":"code","source":"# Make predictions with model\npred_prob = model_fine_tuned.predict(test)","metadata":{"execution":{"iopub.status.busy":"2023-07-19T09:17:30.297013Z","iopub.execute_input":"2023-07-19T09:17:30.297320Z","iopub.status.idle":"2023-07-19T09:18:25.331524Z","shell.execute_reply.started":"2023-07-19T09:17:30.297293Z","shell.execute_reply":"2023-07-19T09:18:25.330494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# How many predictions are there ?\nlen(pred_prob)","metadata":{"execution":{"iopub.status.busy":"2023-07-19T09:18:25.334566Z","iopub.execute_input":"2023-07-19T09:18:25.335524Z","iopub.status.idle":"2023-07-19T09:18:25.342356Z","shell.execute_reply.started":"2023-07-19T09:18:25.335472Z","shell.execute_reply":"2023-07-19T09:18:25.341255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the shape of predictions\npred_prob.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-19T09:18:25.345557Z","iopub.execute_input":"2023-07-19T09:18:25.345933Z","iopub.status.idle":"2023-07-19T09:18:25.356381Z","shell.execute_reply.started":"2023-07-19T09:18:25.345899Z","shell.execute_reply":"2023-07-19T09:18:25.355210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's see what the first 5 predictions look like\npred_prob[:5]","metadata":{"execution":{"iopub.status.busy":"2023-07-19T09:18:25.357879Z","iopub.execute_input":"2023-07-19T09:18:25.358379Z","iopub.status.idle":"2023-07-19T09:18:25.377327Z","shell.execute_reply.started":"2023-07-19T09:18:25.358341Z","shell.execute_reply":"2023-07-19T09:18:25.376276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# what does the first prediction probability array look like ?\npred_prob[0] , len(pred_prob[0]), sum(pred_prob[0])","metadata":{"execution":{"iopub.status.busy":"2023-07-19T09:18:25.378759Z","iopub.execute_input":"2023-07-19T09:18:25.379422Z","iopub.status.idle":"2023-07-19T09:18:25.391126Z","shell.execute_reply.started":"2023-07-19T09:18:25.379386Z","shell.execute_reply":"2023-07-19T09:18:25.389992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our model outputs a prediction probability array(with N number of variables, where N is the number of classes) for each sample passed to the predict model.","metadata":{}},{"cell_type":"code","source":"# We get onr prediction per class(101)\nprint(f\"Number of prediction probabilities for sample 0 : {len(pred_prob[0])}\")\nprint(f\"What prediciton probability of sample 0 looks like: \\n{pred_prob[0]}\")\nprint(f\"The class with highest predicted probability by the model for sample 0 is: {pred_prob[0].argmax()}\" )","metadata":{"execution":{"iopub.status.busy":"2023-07-19T09:18:25.392647Z","iopub.execute_input":"2023-07-19T09:18:25.393470Z","iopub.status.idle":"2023-07-19T09:18:25.403178Z","shell.execute_reply.started":"2023-07-19T09:18:25.393433Z","shell.execute_reply":"2023-07-19T09:18:25.402081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the predicted  classes of each label\npred_classes = pred_prob.argmax(axis=1)\n\n# How do they look?\npred_classes[:10]","metadata":{"execution":{"iopub.status.busy":"2023-07-19T09:18:25.404462Z","iopub.execute_input":"2023-07-19T09:18:25.405136Z","iopub.status.idle":"2023-07-19T09:18:25.418050Z","shell.execute_reply.started":"2023-07-19T09:18:25.405103Z","shell.execute_reply":"2023-07-19T09:18:25.417029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# How many pred_classes we have?\nlen(pred_classes)","metadata":{"execution":{"iopub.status.busy":"2023-07-19T09:18:25.419401Z","iopub.execute_input":"2023-07-19T09:18:25.420467Z","iopub.status.idle":"2023-07-19T09:18:25.426266Z","shell.execute_reply.started":"2023-07-19T09:18:25.420435Z","shell.execute_reply":"2023-07-19T09:18:25.425228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we've got a predictions array of all our model's predictions, to evaluate them , we need to compare them to original test dataset","metadata":{"execution":{"iopub.status.busy":"2023-07-18T09:50:22.088803Z","iopub.execute_input":"2023-07-18T09:50:22.089169Z","iopub.status.idle":"2023-07-18T09:50:22.133313Z","shell.execute_reply.started":"2023-07-18T09:50:22.089137Z","shell.execute_reply":"2023-07-18T09:50:22.132210Z"}}},{"cell_type":"code","source":"# To get the test labels we need to unravel our test_data PrefetchDataset\n# labels = tf.expand_dims(labels, 0)\ny_labels = []\nfor images, labels in test.unbatch():\n    labels = tf.expand_dims(labels, 0)  # Expand dimensions of labels\n    y_labels.append(labels[0].numpy())\ny_labels[:10]","metadata":{"execution":{"iopub.status.busy":"2023-07-19T09:18:25.430676Z","iopub.execute_input":"2023-07-19T09:18:25.431589Z","iopub.status.idle":"2023-07-19T09:19:47.461861Z","shell.execute_reply.started":"2023-07-19T09:18:25.431556Z","shell.execute_reply":"2023-07-19T09:19:47.460875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(y_labels)","metadata":{"execution":{"iopub.status.busy":"2023-07-19T09:19:47.463462Z","iopub.execute_input":"2023-07-19T09:19:47.464076Z","iopub.status.idle":"2023-07-19T09:19:47.470605Z","shell.execute_reply.started":"2023-07-19T09:19:47.464039Z","shell.execute_reply":"2023-07-19T09:19:47.469494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluating the model's predictions \nOne way to check that our model's predictions array is in the same order as our test labels array is to find the accuracy score","metadata":{}},{"cell_type":"code","source":"results_fine_tuned_model","metadata":{"execution":{"iopub.status.busy":"2023-07-19T09:19:47.472249Z","iopub.execute_input":"2023-07-19T09:19:47.472595Z","iopub.status.idle":"2023-07-19T09:19:47.483809Z","shell.execute_reply.started":"2023-07-19T09:19:47.472564Z","shell.execute_reply":"2023-07-19T09:19:47.482817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's try scikit-learn's accuracy score function and see what it comes up with\nfrom sklearn.metrics import accuracy_score\n\nsklearn_accuracy = accuracy_score(y_true=y_labels, y_pred=pred_classes)","metadata":{"execution":{"iopub.status.busy":"2023-07-19T09:19:47.485467Z","iopub.execute_input":"2023-07-19T09:19:47.485803Z","iopub.status.idle":"2023-07-19T09:19:47.502055Z","shell.execute_reply.started":"2023-07-19T09:19:47.485773Z","shell.execute_reply":"2023-07-19T09:19:47.501032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sklearn_accuracy","metadata":{"execution":{"iopub.status.busy":"2023-07-19T09:19:47.505352Z","iopub.execute_input":"2023-07-19T09:19:47.505630Z","iopub.status.idle":"2023-07-19T09:19:47.515292Z","shell.execute_reply.started":"2023-07-19T09:19:47.505597Z","shell.execute_reply":"2023-07-19T09:19:47.514198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Let's get visual: making a confusion matrix ","metadata":{}},{"cell_type":"code","source":"from helper_functions import make_confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2023-07-19T09:19:47.516908Z","iopub.execute_input":"2023-07-19T09:19:47.517683Z","iopub.status.idle":"2023-07-19T09:19:47.522505Z","shell.execute_reply.started":"2023-07-19T09:19:47.517647Z","shell.execute_reply":"2023-07-19T09:19:47.521357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\n\ndef make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False):\n  \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n\n  If classes is passed, confusion matrix will be labelled, if not, integer class values\n  will be used.\n\n  Args:\n    y_true: Array of truth labels (must be same shape as y_pred).\n    y_pred: Array of predicted labels (must be same shape as y_true).\n    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n    figsize: Size of output figure (default=(10, 10)).\n    text_size: Size of output figure text (default=15).\n    norm: normalize values or not (default=False).\n    savefig: save confusion matrix to file (default=False).\n\n  Returns:\n    A labelled confusion matrix plot comparing y_true and y_pred.\n\n  Example usage:\n    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n                          y_pred=y_preds, # predicted labels\n                          classes=class_names, # array of class label names\n                          figsize=(15, 15),\n                          text_size=10)\n  \"\"\"\n  # Create the confustion matrix\n  cm = confusion_matrix(y_true, y_pred)\n  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n  n_classes = cm.shape[0] # find the number of classes we're dealing with\n\n  # Plot the figure and make it pretty\n  fig, ax = plt.subplots(figsize=figsize)\n  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n  fig.colorbar(cax)\n\n  # Are there a list of classes?\n  if classes:\n    labels = classes\n  else:\n    labels = np.arange(cm.shape[0])\n\n  # Label the axes\n  ax.set(title=\"Confusion Matrix\",\n         xlabel=\"Predicted label\",\n         ylabel=\"True label\",\n         xticks=np.arange(n_classes), # create enough axis slots for each class\n         yticks=np.arange(n_classes),\n         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n         yticklabels=labels)\n\n  # Make x-axis labels appear on bottom\n  ax.xaxis.set_label_position(\"bottom\")\n  ax.xaxis.tick_bottom()\n\n  ### Changed (plot x-labels vetically)###\n  plt.xticks(rotation=70, fontsize=text_size)\n  plt.yticks(fontsize=text_size)\n\n  # Set the threshold for different colors\n  threshold = (cm.max() + cm.min()) / 2.\n\n  # Plot the text on each cell\n  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    if norm:\n      plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n              horizontalalignment=\"center\",\n              color=\"white\" if cm[i, j] > threshold else \"black\",\n              size=text_size)\n    else:\n      plt.text(j, i, f\"{cm[i, j]}\",\n              horizontalalignment=\"center\",\n              color=\"white\" if cm[i, j] > threshold else \"black\",\n              size=text_size)\n\n  # Save the figure to the current working directory\n  if savefig:\n    fig.savefig(\"confusion_matrix.png\")","metadata":{"execution":{"iopub.status.busy":"2023-07-19T07:04:47.874906Z","iopub.execute_input":"2023-07-19T07:04:47.875309Z","iopub.status.idle":"2023-07-19T07:04:47.890987Z","shell.execute_reply.started":"2023-07-19T07:04:47.875244Z","shell.execute_reply":"2023-07-19T07:04:47.889791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_confusion_matrix(y_true=y_labels,\n                     y_pred=pred_classes,\n                     classes=class_names,\n                     figsize=(100,100),\n                     text_size=20,\n                     savefig=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-19T07:04:49.944212Z","iopub.execute_input":"2023-07-19T07:04:49.944792Z","iopub.status.idle":"2023-07-19T07:05:41.091814Z","shell.execute_reply.started":"2023-07-19T07:04:49.944748Z","shell.execute_reply":"2023-07-19T07:05:41.090767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Let's keep the evaluation train going on, time for a classification report ","metadata":{}},{"cell_type":"markdown","source":"SciKit-learn has a helpful function fro acquiring many different classification metrics class(e.g. precision, recall and F1) called classification_report, let's try it out","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report \nprint(classification_report(y_true=y_labels,\n                           y_pred=pred_classes))","metadata":{"execution":{"iopub.status.busy":"2023-07-19T09:19:47.523684Z","iopub.execute_input":"2023-07-19T09:19:47.524492Z","iopub.status.idle":"2023-07-19T09:19:47.627838Z","shell.execute_reply.started":"2023-07-19T09:19:47.524460Z","shell.execute_reply":"2023-07-19T09:19:47.625889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get a dictionary of the classification report \nclassification_report_dict = classification_report(y_labels, pred_classes, output_dict=True)\nclassification_report_dict","metadata":{"execution":{"iopub.status.busy":"2023-07-19T09:19:47.629037Z","iopub.execute_input":"2023-07-19T09:19:47.629423Z","iopub.status.idle":"2023-07-19T09:19:47.746486Z","shell.execute_reply.started":"2023-07-19T09:19:47.629387Z","shell.execute_reply":"2023-07-19T09:19:47.745327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's plot all F1-scores","metadata":{}},{"cell_type":"code","source":"#Create a empty dictionary\nclass_f1_scores= {}\n\n# Loop through classifiation report dictionary items\nfor key, value in classification_report_dict.items():\n    if key == \"accuracy\": # stop once we get accuracy key\n        break\n    else:\n        #Add class names and F1 scores to new dict\n        class_f1_scores[class_names[int(key)]] = value[\"f1-score\"]\nclass_f1_scores","metadata":{"execution":{"iopub.status.busy":"2023-07-19T09:19:47.748250Z","iopub.execute_input":"2023-07-19T09:19:47.748589Z","iopub.status.idle":"2023-07-19T09:19:47.760441Z","shell.execute_reply.started":"2023-07-19T09:19:47.748558Z","shell.execute_reply":"2023-07-19T09:19:47.759484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Turn f1 scores into dataframe for visualization \nimport pandas as pd\nf1_scores = pd.DataFrame({\"class_names\": list(class_f1_scores.keys()),\n                          \"f1-score\" : list(class_f1_scores.values())}).sort_values(\"f1-score\", ascending=False)","metadata":{"execution":{"iopub.status.busy":"2023-07-19T09:19:47.761820Z","iopub.execute_input":"2023-07-19T09:19:47.762374Z","iopub.status.idle":"2023-07-19T09:19:47.796941Z","shell.execute_reply.started":"2023-07-19T09:19:47.762341Z","shell.execute_reply":"2023-07-19T09:19:47.795651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_scores","metadata":{"execution":{"iopub.status.busy":"2023-07-19T09:19:47.798326Z","iopub.execute_input":"2023-07-19T09:19:47.798678Z","iopub.status.idle":"2023-07-19T09:19:47.820459Z","shell.execute_reply.started":"2023-07-19T09:19:47.798646Z","shell.execute_reply":"2023-07-19T09:19:47.819457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(12,25))\n\n# PLot the horizontal bars\nscores = ax.barh(range(len(f1_scores)), f1_scores[\"f1-score\"].values)\n\n# Set the y-ticks and labels\nax.set_yticks(range(len(f1_scores)))\nax.set_yticklabels(f1_scores[\"class_names\"])\n\n# Set the x-label and title\nax.set_xlabel(\"F1-score\")\nax.set_title(\"F1-scores for 101 Different Food Classes(predicited by food vision model)\")\n\n# Invert the y-axis\nax.invert_yaxis()\n\n# Add labels to the bars\nfor i , score in enumerate(f1_scores[\"f1-score\"].values):\n    ax.text(score, i, f\"{score:.2f}\", ha=\"left\", va=\"center\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-19T09:19:47.822131Z","iopub.execute_input":"2023-07-19T09:19:47.822508Z","iopub.status.idle":"2023-07-19T09:19:49.313822Z","shell.execute_reply.started":"2023-07-19T09:19:47.822476Z","shell.execute_reply":"2023-07-19T09:19:49.312924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing prediction on custom images\nNow, this is the real test, how does our model go on food images not even in our test dataset(images of our own)\n\nTo visualize our model's predictions on our own images, we'll need a function to load and preprocess images, specifically it will need to:\n* Resize the image to be in the same size as the images our model has trained on using tf.image.resize()\n* Scale the image to get all of the pixel values between 0 & 1(if necessary)","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\ndef load_and_prep_img(image, label, img_shape=224):\n    \"\"\"\n    Converts image datatype from 'uint8' -> 'float32' and reshapes\n    image to [img_shape, img_shape, color_channels]\n    \"\"\"\n    image = tf.image.resize(image, [img_shape, img_shape])  # reshape target image\n#     image = tf.cast(image, tf.int64)  # Convert to float32\n    return image, label  # return (float32_image, label)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-19T09:19:49.315143Z","iopub.execute_input":"2023-07-19T09:19:49.316342Z","iopub.status.idle":"2023-07-19T09:19:49.322803Z","shell.execute_reply.started":"2023-07-19T09:19:49.316246Z","shell.execute_reply":"2023-07-19T09:19:49.321603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we've got a function to load and prepare target images, let's now write some code to visualize images, their target label predictions. Specifically, we'll write some code to:\n\n1. Load a few random images from the test dataset\n2. Make predictions on the loaded images\n3. Plot the original image(s) along with the model's predictions, prediction probability and truth label","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport random\n\ndef plot_random_images(test_data, model, class_labels, num_images=9, img_shape=224):\n    \"\"\"\n    Plots a batch of random images from the test dataset and displays their true labels, predicted labels,\n    and prediction probabilities.\n\n    Parameters:\n        test_data (tf.data.Dataset): The test dataset containing images and labels.\n        model (tf.keras.Model): The trained model used for making predictions.\n        class_labels (list): A list of class labels corresponding to the model's output classes.\n        num_images (int): The number of random images to plot. Default is 9.\n        img_shape (int): The desired shape of the images (img_shape x img_shape). Default is 224.\n\n    Returns:\n        None (plots the images and labels using matplotlib).\n    \"\"\"\n    # Get a random batch of unique indices from the test dataset\n    random_indices = random.sample(range(len(test_data)), num_images)\n\n    # Initialize lists to store the images, true labels, and predicted labels\n    batch_images = []\n    true_labels = []\n    predicted_labels = []\n\n    # Fetch the images and labels for the random indices\n    for i, (image, label) in enumerate(test_data):\n        if i in random_indices:\n            # Preprocess the image\n            image, label = preprocess_img(image, label, img_shape)\n\n            # Add the preprocessed image, true label, and corresponding index to the respective lists\n            batch_images.append(image)\n            true_labels.append(class_labels[label.numpy()])\n            random_indices.remove(i)  # Remove the index from the list to ensure uniqueness\n\n            # Make a prediction using the model\n            prediction = model.predict(tf.expand_dims(image, axis=0))\n            predicted_labels.append(class_labels[prediction.argmax()])\n\n    # Plot the batch of images\n    plt.figure(figsize=(17, 15))\n    for i in range(num_images):\n        image = batch_images[i]\n        true_label = true_labels[i]\n        predicted_label = predicted_labels[i]\n\n        plt.subplot(3, 3, i+1)\n        plt.imshow(image / 255.)\n\n        if true_label == predicted_label:  # If predicted class matches true class, make text green\n            title_color = \"g\"\n        else:\n            title_color = \"r\"\n        plt.title(f\"True Label: {true_label}, \\n Predicted Label: {predicted_label},\\n Prob: {prediction.max():.2f}\", color=title_color)\n        plt.axis(False)\n\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-07-19T09:52:23.636731Z","iopub.execute_input":"2023-07-19T09:52:23.637101Z","iopub.status.idle":"2023-07-19T09:52:26.995349Z","shell.execute_reply.started":"2023-07-19T09:52:23.637071Z","shell.execute_reply":"2023-07-19T09:52:26.994251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Finding the most wrong Predictions\n\nIt's a good idea to go through at least 100+ random instances of your model's predictions to get a good feel for how it's doing.\n\nAfter a while you might notice the model predicting on some images with a very high prediction probability, meaning it's very confident with its prediction but still getting the label wrong.\n\nThese most wrong predictions can help to give further insight into your model's performance.\n\nSo how about we write some code to collect all of the predictions where the model has output a high prediction probability for an image (e.g. 0.95+) but gotten the prediction wrong.\n\nWe'll go through the following steps:\n\n1. Get all of the image file paths in the test dataset using the list_files() method.\n2. Create a pandas DataFrame of the image filepaths, ground truth labels, prediction classes, max prediction probabilities, ground truth class names and predicted class names.\n\n* **Note:** We don't necessarily have to create a DataFrame like this but it'll help us visualize things as we go.\n\n3. Use our DataFrame to find all the wrong predictions (where the ground truth doesn't match the prediction).\n4. Sort the DataFrame based on wrong predictions and highest max prediction probabilities.\n5. Visualize the images with the highest prediction probabilities but have the wrong prediction.\n","metadata":{}},{"cell_type":"code","source":"## TO do this is not working\n# 1. Get the filenames of all of our test data\nfilepaths = []\nfor filepath in test_data.list_files(\"/root/tensorflow_datasets/food101/2.0.0\", \n                                     shuffle=False):\n  filepaths.append(filepath.numpy())\nfilepaths[:]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2. Create a dataframe out of current prediction data for analysis\nimport pandas as pd\npred_df = pd.DataFrame({\"y_true\": y_labels,\n                        \"y_pred\": pred_classes,\n                        \"pred_conf\": pred_prob.max(axis=1), # get the maximum prediction probability value\n                        \"y_true_classname\": [class_names[i] for i in y_labels],\n                        \"y_pred_classname\": [class_names[i] for i in pred_classes]}) \npred_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3. Is the prediction correct?\npred_df[\"pred_correct\"] = pred_df[\"y_true\"] == pred_df[\"y_pred\"]\npred_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And now since we know which predictions were right or wrong and along with their prediction probabilities, how about we get the 100 \"most wrong\" predictions by sorting for wrong predictions and descending prediction probabilties?","metadata":{}},{"cell_type":"code","source":"# 4. Get the top 100 wrong examples\ntop_100_wrong = pred_df[pred_df[\"pred_correct\"] == False].sort_values(\"pred_conf\", ascending=False)[:100]\ntop_100_wrong.head(10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Very interesting... just by comparing the ground truth classname (y_true_classname) and the prediction classname column (y_pred_classname), do you notice any trends?\n\nIt might be easier if we visualize them.","metadata":{}},{"cell_type":"code","source":"## TO do","metadata":{},"execution_count":null,"outputs":[]}]}