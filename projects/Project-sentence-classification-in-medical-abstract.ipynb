{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project: SkimLit ðŸ“„ðŸ”¥\n",
        "Skimming literature\n",
        "\n",
        "The purpose of this notebook is to build an NLP model to make reading medical abstracts easier.\n",
        "\n",
        "More specificially, we're going to be replicating the deep learning model behind the 2017 paper [PubMed 200k RCT: a Dataset for Sequenctial Sentence Classification in Medical Abstracts.](https://arxiv.org/abs/1710.06071)\n",
        "\n",
        "When it was released, the paper presented a new dataset called PubMed 200k RCT which consists of ~200,000 labelled Randomized Controlled Trial (RCT) abstracts.\n",
        "\n",
        "The goal of the dataset was to explore the ability for NLP models to classify sentences which appear in sequential order.\n",
        "\n",
        "The paper we're replicating(the source of the dataset that we'll be using) is available here: https://arxiv.org/abs/1710.06071\n",
        "\n",
        "And reading through the paper above, we see that the model architecture that they use to achieve their best reuslts is available at: https://arxiv.org/abs/1612.05251\n",
        "\n"
      ],
      "metadata": {
        "id": "bxwqLldZQ0s7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confirm access to GPU\n"
      ],
      "metadata": {
        "id": "aRo6dkO5SZOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia -smi -L"
      ],
      "metadata": {
        "id": "6G6n7GQYSrCm",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:19:06.912881Z",
          "iopub.execute_input": "2023-08-05T05:19:06.913289Z",
          "iopub.status.idle": "2023-08-05T05:19:07.942733Z",
          "shell.execute_reply.started": "2023-08-05T05:19:06.913250Z",
          "shell.execute_reply": "2023-08-05T05:19:07.941383Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get data\n",
        "\n",
        "Since we'll be replicating the paper above(Pubmed 200k RCT). let's download the dataset they used.\n",
        "\n",
        "We can do so from the authors Github: https://github.com/Franck-Dernoncourt/pubmed-rct\n"
      ],
      "metadata": {
        "id": "6U8nxP58SuLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct\n",
        "!ls pubmed-rct"
      ],
      "metadata": {
        "id": "po7dqZSWTlFz",
        "outputId": "ce5a075f-f56a-46ef-ff51-a62a659f6628",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:19:07.945367Z",
          "iopub.execute_input": "2023-08-05T05:19:07.946090Z",
          "iopub.status.idle": "2023-08-05T05:19:09.837260Z",
          "shell.execute_reply.started": "2023-08-05T05:19:07.946045Z",
          "shell.execute_reply": "2023-08-05T05:19:09.836062Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pubmed-rct'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 33 (delta 5), reused 5 (delta 5), pack-reused 25\u001b[K\n",
            "Receiving objects: 100% (33/33), 177.08 MiB | 39.57 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n",
            "PubMed_200k_RCT\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_20k_RCT\n",
            "PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To begin with, the dataset we're going to be focused on is `PubMed_20k_RCT_numbers_replaced_with_at_sign`.\n",
        "\n",
        "Why this one?\n",
        "\n",
        "Rather than working with the whole 200k dataset, we'll keep our experiments quick by starting with a smaller subset. We could've chosen the dataset with numbers instead of having them replaced with @ but we didn't.\n",
        "\n",
        "Let's check the file contents."
      ],
      "metadata": {
        "id": "EJ9rrXt5YWiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check what files are in the Pubmed_20k dataset\n",
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/"
      ],
      "metadata": {
        "id": "HbykhC4DUMJ_",
        "outputId": "7e41a65b-6ad7-4e06-a5af-e4408f1b02d6",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:19:09.839093Z",
          "iopub.execute_input": "2023-08-05T05:19:09.839709Z",
          "iopub.status.idle": "2023-08-05T05:19:10.779555Z",
          "shell.execute_reply.started": "2023-08-05T05:19:09.839669Z",
          "shell.execute_reply": "2023-08-05T05:19:10.778241Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.txt  test.txt  train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beautiful, looks like we've got three separate text files:\n",
        "\n",
        "* `train.txt` - training samples.\n",
        "* `dev.txt` - dev is short for development set, which is another name for validation set (in our case, we'll be using and referring to this file as our validation set).\n",
        "* `test.txt` - test samples."
      ],
      "metadata": {
        "id": "G4wxncUeYfCO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To save ourselves typing out the filepath to our target directory each time, let's turn it into a variable."
      ],
      "metadata": {
        "id": "Q4EHgf0EYrGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start our experiments using the 20k dataset with numbers replaced by \"@\" sign\n",
        "data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
      ],
      "metadata": {
        "id": "vNBwUv09VBFd",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:08.634467Z",
          "iopub.execute_input": "2023-08-05T05:21:08.634835Z",
          "iopub.status.idle": "2023-08-05T05:21:08.639246Z",
          "shell.execute_reply.started": "2023-08-05T05:21:08.634804Z",
          "shell.execute_reply": "2023-08-05T05:21:08.638237Z"
        },
        "trusted": true
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check all of the filenames in the target directory\n",
        "import os\n",
        "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
        "filenames"
      ],
      "metadata": {
        "id": "Lj_fVWDPWOBU",
        "outputId": "dd711020-5142-4868-f201-d8061c065221",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:09.180824Z",
          "iopub.execute_input": "2023-08-05T05:21:09.181244Z",
          "iopub.status.idle": "2023-08-05T05:21:09.189110Z",
          "shell.execute_reply.started": "2023-08-05T05:21:09.181205Z",
          "shell.execute_reply": "2023-08-05T05:21:09.188000Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess the data\n",
        "\n",
        "Now we've got some text data, it's time to become one with it.\n",
        "\n",
        "And one the best ways to become one with the data is to..,\n",
        "> Visulize..Visualize..Visualize\n",
        "\n",
        "So with that in the mind, let's write a function to read in all of the lines of a target text file"
      ],
      "metadata": {
        "id": "BfSJ_qemWlf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to read the lines of a document\n",
        "def get_lines(filename):\n",
        "  \"\"\"\n",
        "  Reads filename (a text filename) and returns the lines of text as a list.\n",
        "\n",
        "  Args:\n",
        "    filename: a string containing the target filepath.\n",
        "\n",
        "  Returns:\n",
        "    A list of strings with one string per line from the target filename.\n",
        "  \"\"\"\n",
        "  with open(filename, \"r\") as f:\n",
        "    return f.readlines()"
      ],
      "metadata": {
        "id": "UMK9ilpSXk_l",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:11.623086Z",
          "iopub.execute_input": "2023-08-05T05:21:11.623815Z",
          "iopub.status.idle": "2023-08-05T05:21:11.631090Z",
          "shell.execute_reply.started": "2023-08-05T05:21:11.623781Z",
          "shell.execute_reply": "2023-08-05T05:21:11.628334Z"
        },
        "trusted": true
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's read in the training lines\n",
        "train_lines = get_lines(data_dir+\"train.txt\") #Read the lines with the training files\n",
        "train_lines[:20]"
      ],
      "metadata": {
        "id": "g4QizVfSYaRE",
        "outputId": "93d159ce-2d1c-45da-b79c-8002e167af41",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:12.610493Z",
          "iopub.execute_input": "2023-08-05T05:21:12.610850Z",
          "iopub.status.idle": "2023-08-05T05:21:12.681142Z",
          "shell.execute_reply.started": "2023-08-05T05:21:12.610821Z",
          "shell.execute_reply": "2023-08-05T05:21:12.680030Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24293578\\n',\n",
              " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
              " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
              " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
              " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
              " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
              " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
              " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
              " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
              " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
              " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
              " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
              " '\\n',\n",
              " '###24854809\\n',\n",
              " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
              " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
              " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
              " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
              " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_lines)"
      ],
      "metadata": {
        "id": "I7N68Z2CZCke",
        "outputId": "d9a9b19e-d0f8-426c-f6b0-eeae104e37f4",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:15.366960Z",
          "iopub.execute_input": "2023-08-05T05:21:15.367350Z",
          "iopub.status.idle": "2023-08-05T05:21:15.374517Z",
          "shell.execute_reply.started": "2023-08-05T05:21:15.367318Z",
          "shell.execute_reply": "2023-08-05T05:21:15.373525Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "210040"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading the lines from the training text file results in a list of strings containing different abstract samples, the sentences in a sample along with the role the sentence plays in the abstract.\n",
        "\n",
        "The role of each sentence is prefixed at the start of each line separated by a tab (`\\t`) and each sentence finishes with a new line (`\\n`).\n",
        "\n",
        "Different abstracts are separated by abstract ID's (lines beginning with `###`) and newlines (`\\n`).\n",
        "\n",
        "Knowing this, it looks like we've got a couple of steps to do to get our samples ready to pass as training data to our future machine learning model.\n",
        "Let's think about how we want our data to look...\n",
        "\n",
        "let's try thiss...\n",
        "```\n",
        "[{'line_number': 0,\n",
        "  'target': 'BACKGROUND',\n",
        "  'text': \"Emotional eating is associated with overeating and the development of obesity .\\n\",\n",
        "  'total_lines': 11},\n",
        "  ...]\n",
        "```"
      ],
      "metadata": {
        "id": "nNMGXKQweFUB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's write a function which turns each of our datasets into the above format so we can continue to prepare our data for modelling."
      ],
      "metadata": {
        "id": "ArkKvM4Of_DU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text_with_line_numbers(filename):\n",
        "  \"\"\"\n",
        "  Returns a list of dictionaries of abstract line data.\n",
        "\n",
        "  Takes in filename, reads it contents and sorts  through each line, extracting things\n",
        "  like the target label, the text of the sentence, how many sentences are in the current\n",
        "  abstract and what sentence number the target line is.\n",
        "  \"\"\"\n",
        "  input_lines = get_lines(filename) # get all lines from filename\n",
        "  abstract_lines = \"\"  # create an empty abstract\n",
        "  abstract_samples = [] # create an empty list of abstracts\n",
        "\n",
        "  # loop through each line in the target file\n",
        "  for line in input_lines:\n",
        "    if line.startswith(\"###\"): #check to see if the line is an ID line\n",
        "      abstract_id = line\n",
        "      abstract_lines = \"\" #reset the abstract string if the line is an id line\n",
        "    elif line.isspace(): # Check to see if line is a new line\n",
        "      abstract_line_split = abstract_lines.splitlines() #split abstract into separate lines\n",
        "\n",
        "      # Iterate through each line in a single abstract and count them at same time\n",
        "      for abstract_line_number , abstract_line in enumerate(abstract_line_split):\n",
        "        line_data = {} # creates a empty dictionary for each line\n",
        "        target_text_split = abstract_line.split(\"\\t\") # Split target labels from text\n",
        "        line_data[\"target\"] = target_text_split[0] # get the target label\n",
        "        line_data[\"text\"] = target_text_split[1].lower() #get the target text and lower it\n",
        "        line_data[\"line_number\"] = abstract_line_number # what number line does the line appear in the abstract\n",
        "        line_data[\"total_lines\"] = len(abstract_line_split) - 1 # how many total lines are there in the target abstract? (start from 0)\n",
        "        abstract_samples.append(line_data) # add line data to abstract samples list\n",
        "\n",
        "    else: #if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
        "      abstract_lines += line\n",
        "\n",
        "  return abstract_samples"
      ],
      "metadata": {
        "id": "UrnW3cIrhMtH",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:20.626624Z",
          "iopub.execute_input": "2023-08-05T05:21:20.626976Z",
          "iopub.status.idle": "2023-08-05T05:21:20.636651Z",
          "shell.execute_reply.started": "2023-08-05T05:21:20.626945Z",
          "shell.execute_reply": "2023-08-05T05:21:20.635601Z"
        },
        "trusted": true
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get data from file and preprocess it\n",
        "%time\n",
        "train_samples = preprocess_text_with_line_numbers(data_dir +\"train.txt\")\n",
        "val_samples = preprocess_text_with_line_numbers(data_dir +\"dev.txt\")\n",
        "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
        "print(len(train_samples), len(test_samples), len(val_samples) )"
      ],
      "metadata": {
        "id": "qCuwwaNQl-Jc",
        "outputId": "f2e0f366-baf9-4742-948d-21bb5c46cd5e",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:31.994099Z",
          "iopub.execute_input": "2023-08-05T05:21:31.994825Z",
          "iopub.status.idle": "2023-08-05T05:21:32.778953Z",
          "shell.execute_reply.started": "2023-08-05T05:21:31.994789Z",
          "shell.execute_reply": "2023-08-05T05:21:32.777966Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2 Âµs, sys: 1e+03 ns, total: 3 Âµs\n",
            "Wall time: 6.2 Âµs\n",
            "180040 30135 30212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the first abstract of our training data\n",
        "train_samples[:10]"
      ],
      "metadata": {
        "id": "eDdXLjDOoQuT",
        "outputId": "a477b2d4-b6d2-404f-8223-f49b19fb3988",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:36.119416Z",
          "iopub.execute_input": "2023-08-05T05:21:36.119781Z",
          "iopub.status.idle": "2023-08-05T05:21:36.128123Z",
          "shell.execute_reply.started": "2023-08-05T05:21:36.119750Z",
          "shell.execute_reply": "2023-08-05T05:21:36.127189Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'target': 'OBJECTIVE',\n",
              "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              "  'line_number': 0,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              "  'line_number': 1,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              "  'line_number': 2,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              "  'line_number': 3,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              "  'line_number': 4,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              "  'line_number': 5,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              "  'line_number': 6,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              "  'line_number': 7,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              "  'line_number': 8,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'these differences remained significant at @ weeks .',\n",
              "  'line_number': 9,\n",
              "  'total_lines': 11}]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fantastic! Looks like our `preprocess_text_with_line_numbers() `function worked great."
      ],
      "metadata": {
        "id": "_oR8gyPDZqyV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our data is the format of a list of dictionaries, how about we run it into\n",
        "a DataFrame to further visualize it."
      ],
      "metadata": {
        "id": "gsTf0ZLEo4KZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_df  = pd.DataFrame(train_samples)\n",
        "val_df = pd.DataFrame(val_samples)\n",
        "test_df = pd.DataFrame(test_samples)\n",
        "train_df.head(10)"
      ],
      "metadata": {
        "id": "m2DHyJ6If6OH",
        "outputId": "7d13f217-a82d-49f4-8403-f50cf29eefa3",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:36.130033Z",
          "iopub.execute_input": "2023-08-05T05:21:36.130622Z",
          "iopub.status.idle": "2023-08-05T05:21:36.594126Z",
          "shell.execute_reply.started": "2023-08-05T05:21:36.130588Z",
          "shell.execute_reply": "2023-08-05T05:21:36.592088Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      target                                               text  line_number  \\\n",
              "0  OBJECTIVE  to investigate the efficacy of @ weeks of dail...            0   \n",
              "1    METHODS  a total of @ patients with primary knee oa wer...            1   \n",
              "2    METHODS  outcome measures included pain reduction and i...            2   \n",
              "3    METHODS  pain was assessed using the visual analog pain...            3   \n",
              "4    METHODS  secondary outcome measures included the wester...            4   \n",
              "5    METHODS  serum levels of interleukin @ ( il-@ ) , il-@ ...            5   \n",
              "6    RESULTS  there was a clinically relevant reduction in t...            6   \n",
              "7    RESULTS  the mean difference between treatment arms ( @...            7   \n",
              "8    RESULTS  further , there was a clinically relevant redu...            8   \n",
              "9    RESULTS  these differences remained significant at @ we...            9   \n",
              "\n",
              "   total_lines  \n",
              "0           11  \n",
              "1           11  \n",
              "2           11  \n",
              "3           11  \n",
              "4           11  \n",
              "5           11  \n",
              "6           11  \n",
              "7           11  \n",
              "8           11  \n",
              "9           11  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bfd2b774-4495-4f68-ab85-404a6432ccfe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>there was a clinically relevant reduction in t...</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the mean difference between treatment arms ( @...</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>further , there was a clinically relevant redu...</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>these differences remained significant at @ we...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bfd2b774-4495-4f68-ab85-404a6432ccfe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bfd2b774-4495-4f68-ab85-404a6432ccfe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bfd2b774-4495-4f68-ab85-404a6432ccfe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9a7d8250-87ac-40a8-b197-aebe84f50e19\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9a7d8250-87ac-40a8-b197-aebe84f50e19')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9a7d8250-87ac-40a8-b197-aebe84f50e19 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of labels in training data\n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "id": "X6TvqXy6gO7o",
        "outputId": "047b1b9b-3d78-48e8-d912-4c97bdf678b7",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:36.595895Z",
          "iopub.execute_input": "2023-08-05T05:21:36.596336Z",
          "iopub.status.idle": "2023-08-05T05:21:36.641288Z",
          "shell.execute_reply.started": "2023-08-05T05:21:36.596299Z",
          "shell.execute_reply": "2023-08-05T05:21:36.640183Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "METHODS        59353\n",
              "RESULTS        57953\n",
              "CONCLUSIONS    27168\n",
              "BACKGROUND     21727\n",
              "OBJECTIVE      13839\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like sentences with the `OBJECTIVE `label are the least common.\n",
        "\n",
        "How about we check the distribution of our abstract lengths?"
      ],
      "metadata": {
        "id": "1ZR26DTMZ4dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check the length of different lines\n",
        "train_df.total_lines.plot.hist();"
      ],
      "metadata": {
        "id": "z2SwltvLgqEG",
        "outputId": "f9153fc7-516e-4df8-9b0d-36f14ba37709",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:36.642829Z",
          "iopub.execute_input": "2023-08-05T05:21:36.643191Z",
          "iopub.status.idle": "2023-08-05T05:21:36.992524Z",
          "shell.execute_reply.started": "2023-08-05T05:21:36.643135Z",
          "shell.execute_reply": "2023-08-05T05:21:36.991592Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay, looks like most of the abstracts are around 7 to 15 sentences in length.\n",
        "\n",
        "It's good to check these things out to make sure when we do train a model or test it on unseen samples, our results aren't outlandish."
      ],
      "metadata": {
        "id": "7obsNpAWaChw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get lists of sentences\n",
        "When we build our deep learning model, one of its main inputs will be a list of strings (the lines of an abstract).\n",
        "\n",
        "We can get these easily from our DataFrames by calling the `tolist()` method on our `\"text\"` columns."
      ],
      "metadata": {
        "id": "47s7IUJgg3Ev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert abstract text lines into lists\n",
        "train_sentences = train_df[\"text\"].tolist()\n",
        "val_sentences = val_df[\"text\"].tolist()\n",
        "test_sentences = test_df[\"text\"].tolist()\n",
        "len(train_sentences), len(val_sentences), len(test_sentences)"
      ],
      "metadata": {
        "id": "iqfeLzsDhAMC",
        "outputId": "2bc593c4-8523-4d7e-e4dc-8dca3c1a2af9",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:36.995305Z",
          "iopub.execute_input": "2023-08-05T05:21:36.995652Z",
          "iopub.status.idle": "2023-08-05T05:21:37.010361Z",
          "shell.execute_reply.started": "2023-08-05T05:21:36.995613Z",
          "shell.execute_reply": "2023-08-05T05:21:37.009446Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 30212, 30135)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the 10 lines of training sentences\n",
        "train_sentences[:10]"
      ],
      "metadata": {
        "id": "3gMqvZm2hf2_",
        "outputId": "fe9d3dd8-29ba-4cc4-dd6a-ca9c71225d32",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:37.011574Z",
          "iopub.execute_input": "2023-08-05T05:21:37.012558Z",
          "iopub.status.idle": "2023-08-05T05:21:37.022000Z",
          "shell.execute_reply.started": "2023-08-05T05:21:37.012518Z",
          "shell.execute_reply": "2023-08-05T05:21:37.020850Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              " 'these differences remained significant at @ weeks .']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make numeric labels (ML models require numeric labels)"
      ],
      "metadata": {
        "id": "GZc5r184hpzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to create one hot and label encoded labels.\n",
        "\n",
        "We could get away with just making label encoded labels, however, TensorFlow's CategoricalCrossentropy loss function likes to have one hot encoded labels (this will enable us to use label smoothing later on).\n",
        "\n",
        "To numerically encode labels we'll use Scikit-Learn's` OneHotEncoder` and `LabelEncoder` classes."
      ],
      "metadata": {
        "id": "0Ln9j6nRaTkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One hot enode labels\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1,1))\n",
        "val_labels_one_hot = one_hot_encoder.transform(val_df[\"target\"].to_numpy().reshape(-1,1))\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_df[\"target\"].to_numpy().reshape(-1,1))\n",
        "\n",
        "# Check what one hot encoded labels look like\n",
        "train_labels_one_hot"
      ],
      "metadata": {
        "id": "syTsjcx9iYVs",
        "outputId": "a5a8fd65-2415-4b53-c4a2-8249e092c5a7",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:37.023513Z",
          "iopub.execute_input": "2023-08-05T05:21:37.023856Z",
          "iopub.status.idle": "2023-08-05T05:21:37.139098Z",
          "shell.execute_reply.started": "2023-08-05T05:21:37.023823Z",
          "shell.execute_reply": "2023-08-05T05:21:37.138011Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Label encode labels"
      ],
      "metadata": {
        "id": "sGH5BDdajOxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract labels (\"target\" columns) and encode them into integers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
        "val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n",
        "test_labels_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())"
      ],
      "metadata": {
        "id": "MYPjJOFRkXUX",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:37.141274Z",
          "iopub.execute_input": "2023-08-05T05:21:37.142027Z",
          "iopub.status.idle": "2023-08-05T05:21:37.216619Z",
          "shell.execute_reply.started": "2023-08-05T05:21:37.141988Z",
          "shell.execute_reply": "2023-08-05T05:21:37.215688Z"
        },
        "trusted": true
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_encoded"
      ],
      "metadata": {
        "id": "obitXfnzkrE-",
        "outputId": "e4fddb6f-d323-430c-fe9f-353e18a83f8a",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:37.218196Z",
          "iopub.execute_input": "2023-08-05T05:21:37.218552Z",
          "iopub.status.idle": "2023-08-05T05:21:37.226376Z",
          "shell.execute_reply.started": "2023-08-05T05:21:37.218518Z",
          "shell.execute_reply": "2023-08-05T05:21:37.225212Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 2, ..., 4, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get class names and number of classes from LabelEncoder instance\n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "num_classes, class_names"
      ],
      "metadata": {
        "id": "ew8eKZf-lWu5",
        "outputId": "fdf45747-3f80-4740-ac98-0e59ff2f3c22",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:37.227801Z",
          "iopub.execute_input": "2023-08-05T05:21:37.228956Z",
          "iopub.status.idle": "2023-08-05T05:21:37.245187Z",
          "shell.execute_reply.started": "2023-08-05T05:21:37.228919Z",
          "shell.execute_reply": "2023-08-05T05:21:37.244232Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5,\n",
              " array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Starting a series of modelling experiments...\n",
        "\n",
        "As usual, we're going to be trying out a bunch of different models and seeing which one works best. And as always, we're going to start with a baseline`(TF-IDF Multinomial Naive Bayes Classifier)`\n",
        "\n",
        "For each model, we'll train it on the training data and evaluate it on the validation data."
      ],
      "metadata": {
        "id": "F6zKW-u1mCI_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 0: Getting a baseline\n",
        "\n",
        "To create our baseline, we'll use Sklearn's Multinomial Naive Bayes using the TF-IDF(Term frequency - inverse document frequency, i.e. tf-idf = tf * idf) formula to convert our words to numbers.\n",
        "\n",
        "> **Note:** It's common practice to use non-Dl algorithms as a baseline because of their speed and then later using Dl to see if you can improve upon them."
      ],
      "metadata": {
        "id": "vgzyNyNdpHSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "YoqC0Q-7pk1-",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:37.251609Z",
          "iopub.execute_input": "2023-08-05T05:21:37.252257Z",
          "iopub.status.idle": "2023-08-05T05:21:37.288836Z",
          "shell.execute_reply.started": "2023-08-05T05:21:37.252223Z",
          "shell.execute_reply": "2023-08-05T05:21:37.287965Z"
        },
        "trusted": true
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    (\"clf\", MultinomialNB()) #MOdel the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels_encoded)"
      ],
      "metadata": {
        "id": "LELwz7KHp5LM",
        "outputId": "077a9134-ee7d-4366-f68d-8d8d4b4c15fb",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:37.290119Z",
          "iopub.execute_input": "2023-08-05T05:21:37.290491Z",
          "iopub.status.idle": "2023-08-05T05:21:44.970119Z",
          "shell.execute_reply.started": "2023-08-05T05:21:37.290458Z",
          "shell.execute_reply": "2023-08-05T05:21:44.969156Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model_0.score(val_sentences, val_labels_encoded)"
      ],
      "metadata": {
        "id": "7jnYyHsqqkrL",
        "outputId": "4de97482-b6a5-42f0-f9f0-792e1d9611d2",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:44.974372Z",
          "iopub.execute_input": "2023-08-05T05:21:44.977071Z",
          "iopub.status.idle": "2023-08-05T05:21:45.910776Z",
          "shell.execute_reply.started": "2023-08-05T05:21:44.977034Z",
          "shell.execute_reply": "2023-08-05T05:21:45.909671Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7218323844829869"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice! Looks like 72.1% accuracy will be the number to beat with our deeper models.\n",
        "\n",
        "Now let's make some predictions with our baseline model to further evaluate it."
      ],
      "metadata": {
        "id": "04rxVIaxbtnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions using our baseline model\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds"
      ],
      "metadata": {
        "id": "MsgnqqHoqwiZ",
        "outputId": "fa99bbe7-c043-44cc-ece7-92e71e6953ae",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:45.912392Z",
          "iopub.execute_input": "2023-08-05T05:21:45.912821Z",
          "iopub.status.idle": "2023-08-05T05:21:46.722839Z",
          "shell.execute_reply.started": "2023-08-05T05:21:45.912786Z",
          "shell.execute_reply": "2023-08-05T05:21:46.721754Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 1, 3, ..., 4, 4, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download helper functions script"
      ],
      "metadata": {
        "id": "8q8N5V1tsDoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/kishan5111/Deep_Learning_Vault/main/notebooks/tensorflow_course/helper_functions.py"
      ],
      "metadata": {
        "id": "5r78BRQ0sSLR",
        "outputId": "6b3cf9c5-6553-4b52-c9c6-79a6bbd279b5",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:46.724465Z",
          "iopub.execute_input": "2023-08-05T05:21:46.724829Z",
          "iopub.status.idle": "2023-08-05T05:21:47.982135Z",
          "shell.execute_reply.started": "2023-08-05T05:21:46.724793Z",
          "shell.execute_reply": "2023-08-05T05:21:47.980935Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-22 05:47:18--  https://raw.githubusercontent.com/kishan5111/Deep_Learning_Vault/main/notebooks/tensorflow_course/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10415 (10K) [text/plain]\n",
            "Saving to: â€˜helper_functions.pyâ€™\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.17K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-09-22 05:47:18 (67.7 MB/s) - â€˜helper_functions.pyâ€™ saved [10415/10415]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import calculate_results"
      ],
      "metadata": {
        "id": "FYP7e7fXsiMm",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:47.984016Z",
          "iopub.execute_input": "2023-08-05T05:21:47.984750Z",
          "iopub.status.idle": "2023-08-05T05:21:58.335004Z",
          "shell.execute_reply.started": "2023-08-05T05:21:47.984709Z",
          "shell.execute_reply": "2023-08-05T05:21:58.334024Z"
        },
        "trusted": true
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calcluate baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                     y_pred = baseline_preds)"
      ],
      "metadata": {
        "id": "py5ixQFvsvEH",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:58.337295Z",
          "iopub.execute_input": "2023-08-05T05:21:58.338512Z",
          "iopub.status.idle": "2023-08-05T05:21:58.357294Z",
          "shell.execute_reply.started": "2023-08-05T05:21:58.338470Z",
          "shell.execute_reply": "2023-08-05T05:21:58.356364Z"
        },
        "trusted": true
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "id": "NzkSyy7wtEHG",
        "outputId": "f62b6576-ace2-4dcc-ff46-fe19442c1058",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:58.358935Z",
          "iopub.execute_input": "2023-08-05T05:21:58.359340Z",
          "iopub.status.idle": "2023-08-05T05:21:58.368263Z",
          "shell.execute_reply.started": "2023-08-05T05:21:58.359303Z",
          "shell.execute_reply": "2023-08-05T05:21:58.365201Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 72.1832384482987,\n",
              " 'precision': 0.7186466952323352,\n",
              " 'recall': 0.7218323844829869,\n",
              " 'f1': 0.6989250353450294}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing our data(the text) for deep sequence model\n",
        "\n",
        "Before we start building deeper models, we've got to create vectorization and embedding layers.  \n",
        "\n",
        "The vectorization layer will convert our text to numbers and the embedding layer will capture the relationships between those numbers.\n",
        "\n",
        "To start creating our vectorization and embedding layers, we'll need to import the appropriate libraries (namely TensorFlow and NumPy).\n"
      ],
      "metadata": {
        "id": "F54S4MdXtF5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "DXKtMgOJWv5P",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:58.369721Z",
          "iopub.execute_input": "2023-08-05T05:21:58.370759Z",
          "iopub.status.idle": "2023-08-05T05:21:58.376497Z",
          "shell.execute_reply.started": "2023-08-05T05:21:58.370724Z",
          "shell.execute_reply": "2023-08-05T05:21:58.375347Z"
        },
        "trusted": true
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we'll be turning our sentences into numbers, it's a good idea to figure out how many words are in each sentence.\n",
        "\n",
        "When our model goes through our sentences, it works best when they're all the same length (this is important for creating batches of the same size tensors).\n",
        "\n",
        "For example, if one sentence is eight words long and another is 29 words long, we want to pad the eight word sentence with zeros so it ends up being the same length as the 29 word sentence.\n",
        "\n",
        "Let's write some code to find the average length of sentences in the training set."
      ],
      "metadata": {
        "id": "gOqf7C4Zc28n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How long is each sentence on average?\n",
        "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
        "avg_sent_len = np.mean(sent_lens)\n",
        "avg_sent_len"
      ],
      "metadata": {
        "id": "Q2ehkWkjZfhP",
        "outputId": "79eb2caa-bb3f-4624-8f0f-45c12b2c0bba",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:58.377899Z",
          "iopub.execute_input": "2023-08-05T05:21:58.378609Z",
          "iopub.status.idle": "2023-08-05T05:21:58.757222Z",
          "shell.execute_reply.started": "2023-08-05T05:21:58.378572Z",
          "shell.execute_reply": "2023-08-05T05:21:58.756087Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.338269273494777"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What's the distribution look like?\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(sent_lens, bins=7);"
      ],
      "metadata": {
        "id": "fCXEpWspZ1Jy",
        "outputId": "55203462-375d-431e-abf2-1878cb290c10",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:58.758823Z",
          "iopub.execute_input": "2023-08-05T05:21:58.759208Z",
          "iopub.status.idle": "2023-08-05T05:21:59.940629Z",
          "shell.execute_reply.started": "2023-08-05T05:21:58.759150Z",
          "shell.execute_reply": "2023-08-05T05:21:59.939422Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like the vast majority of sentences are between 0 and 50 tokens in length.\n",
        "\n",
        "We can use NumPy's `percentile` to find the value which covers 95% of the sentence lengths."
      ],
      "metadata": {
        "id": "hF57XhB1c8Vi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How long of a sentence length covers 95% of examples?\n",
        "output_seq_len = int(np.percentile(sent_lens, 95))\n",
        "output_seq_len"
      ],
      "metadata": {
        "id": "7CLX507Gaffe",
        "outputId": "e8581350-c7ec-40c4-cca5-44ab7ce2417d",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:21:59.945050Z",
          "iopub.execute_input": "2023-08-05T05:21:59.947958Z",
          "iopub.status.idle": "2023-08-05T05:22:00.000734Z",
          "shell.execute_reply.started": "2023-08-05T05:21:59.947920Z",
          "shell.execute_reply": "2023-08-05T05:21:59.999660Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wonderful! It looks like 95% of the sentences in our training set have a length of 55 tokens or less.\n",
        "\n",
        "When we create our tokenization layer, we'll use this value to turn all of our sentences into the same length. Meaning sentences with a length below 55 get padded with zeros and sentences with a length above 55 get truncated (words after 55 get cut off).\n",
        "\n",
        "We could use the max sentence length of the sentences in the training set."
      ],
      "metadata": {
        "id": "DjhYy_hOdFse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Maximum sequence length in the training set?\n",
        "max(sent_lens)"
      ],
      "metadata": {
        "id": "FPxcF2l0beXS",
        "outputId": "fd9eef60-b772-4a62-e5a5-1dc4a5123766",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:22:00.005043Z",
          "iopub.execute_input": "2023-08-05T05:22:00.007735Z",
          "iopub.status.idle": "2023-08-05T05:22:00.023938Z",
          "shell.execute_reply.started": "2023-08-05T05:22:00.007697Z",
          "shell.execute_reply": "2023-08-05T05:22:00.022702Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "296"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, since hardly any sentences even come close to the max length, it would mean the majority of the data we pass to our model would be zeros (sinces all sentences below the max length would get padded with zeros)."
      ],
      "metadata": {
        "id": "CWp4sbtLdT8k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Text Vectorizer"
      ],
      "metadata": {
        "id": "XiMzLv6qb6zC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got a little more information about our texts, let's create a way to turn it into numbers.\n",
        "\n",
        "To do so, we'll use the `TextVectorization `layer from TensorFlow.\n",
        "\n",
        "We'll keep all the parameters default except for` max_tokens` (the number of unique words in our dataset) and `output_sequence_length` (our desired output length for each vectorized sentence)."
      ],
      "metadata": {
        "id": "mohS01yidZyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# How many words are in our vocabulary? (taken from 3.2 in https://arxiv.org/pdf/1710.06071.pdf)\n",
        "max_tokens = 68000\n",
        "\n",
        "# Use the default TextVectorization parameters\n",
        "text_vectorizer = TextVectorization(max_tokens=max_tokens, #how many words in vocabulary(automatically add<OOV>)\n",
        "                                    output_sequence_length=55)"
      ],
      "metadata": {
        "id": "BT3Tfa8LcOjU",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:22:00.028982Z",
          "iopub.execute_input": "2023-08-05T05:22:00.031530Z",
          "iopub.status.idle": "2023-08-05T05:22:05.042174Z",
          "shell.execute_reply.started": "2023-08-05T05:22:00.031494Z",
          "shell.execute_reply": "2023-08-05T05:22:05.041220Z"
        },
        "trusted": true
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapt text vectorizer to training sentences\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "iDhlgxVBdePA",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:22:05.043665Z",
          "iopub.execute_input": "2023-08-05T05:22:05.044011Z",
          "iopub.status.idle": "2023-08-05T05:22:27.856571Z",
          "shell.execute_reply.started": "2023-08-05T05:22:05.043976Z",
          "shell.execute_reply": "2023-08-05T05:22:27.855508Z"
        },
        "trusted": true
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out text vectorizer on random sentences\n",
        "import random\n",
        "target_sentence = random.choice(train_sentences)\n",
        "print(f\"Text:\\n {target_sentence}\")\n",
        "print(f\"\\nLength of text: {len(target_sentence.split())}\")\n",
        "print(f\"\\nVectorized text: {text_vectorizer([target_sentence])}\")"
      ],
      "metadata": {
        "id": "MInR4Su3d0V6",
        "outputId": "b8f437a3-09a5-4f81-8537-e21a662af019",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:22:27.858752Z",
          "iopub.execute_input": "2023-08-05T05:22:27.859237Z",
          "iopub.status.idle": "2023-08-05T05:22:27.961412Z",
          "shell.execute_reply.started": "2023-08-05T05:22:27.859200Z",
          "shell.execute_reply": "2023-08-05T05:22:27.960232Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:\n",
            " recent symptoms stand as a major determinant of stroke risk in patients with carotid stenosis , likely reflective of atherosclerotic plaque destabilization .\n",
            "\n",
            "Length of text: 23\n",
            "\n",
            "Vectorized text: [[  968   144  7008    25     8   347  6417     4   276    73     5    12\n",
            "      7  1839  1484   532  7996     4  5457  1072 17308     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cool, we've now got a way to turn our sequences into numbers."
      ],
      "metadata": {
        "id": "1asPpw6dd6K5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many words in our training vocabulary\n",
        "rct_20k_text_vocab = text_vectorizer.get_vocabulary()\n",
        "print(f\"Number of words in vocab: {len(rct_20k_text_vocab)}\")\n",
        "print(f\"Most common words in the vocab: {rct_20k_text_vocab[:5]}\")\n",
        "print(f\"Least common words in the vocab: {rct_20k_text_vocab[-5:]}\")"
      ],
      "metadata": {
        "id": "9oaiJzypeg8K",
        "outputId": "fe7197f5-03d5-4762-deb7-77b8efbfa824",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:22:27.962763Z",
          "iopub.execute_input": "2023-08-05T05:22:27.963132Z",
          "iopub.status.idle": "2023-08-05T05:22:28.179515Z",
          "shell.execute_reply.started": "2023-08-05T05:22:27.963085Z",
          "shell.execute_reply": "2023-08-05T05:22:28.178339Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 64841\n",
            "Most common words in the vocab: ['', '[UNK]', 'the', 'and', 'of']\n",
            "Least common words in the vocab: ['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And if you wanted to figure out the configuration of text_vectorizer you can use the get_config() method."
      ],
      "metadata": {
        "id": "76AAlGLXeDCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the config of our text vectorizer\n",
        "text_vectorizer.get_config()"
      ],
      "metadata": {
        "id": "AXccGGSCfrJ-",
        "outputId": "a6a8a4ec-8adb-493a-aabb-e370c14b5844",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:22:28.180977Z",
          "iopub.execute_input": "2023-08-05T05:22:28.181350Z",
          "iopub.status.idle": "2023-08-05T05:22:28.188443Z",
          "shell.execute_reply.started": "2023-08-05T05:22:28.181305Z",
          "shell.execute_reply": "2023-08-05T05:22:28.187521Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'text_vectorization_1',\n",
              " 'trainable': True,\n",
              " 'dtype': 'string',\n",
              " 'batch_input_shape': (None,),\n",
              " 'max_tokens': 68000,\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'split': 'whitespace',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': 55,\n",
              " 'pad_to_max_tokens': False,\n",
              " 'sparse': False,\n",
              " 'ragged': False,\n",
              " 'vocabulary': None,\n",
              " 'idf_weights': None,\n",
              " 'encoding': 'utf-8',\n",
              " 'vocabulary_size': 64841}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a custom text embedding\n",
        "\n",
        "Our `token_vectorization` layer maps the words in our text directly to numbers. However, this doesn't necessarily capture the relationships between those numbers.\n",
        "\n",
        "To create a richer numerical representation of our text, we can use an **embedding.**\n",
        "\n",
        "As our model learns (by going through many different examples of abstract sentences and their labels), it'll update its embedding to better represent the relationships between tokens in our corpus.\n",
        "\n",
        "We can create a trainable embedding layer using TensorFlow's `Embedding` layer.\n",
        "\n",
        "Once again, the main parameters we're concerned with here are the inputs and outputs of our `Embedding` layer.\n",
        "\n",
        "The `input_dim` parameter defines the size of our vocabulary. And the `output_dim `parameter defines the dimension of the embedding output.\n",
        "\n",
        "Once created, our embedding layer will take the integer outputs of our `text_vectorization` layer as inputs and convert them to feature vectors of size output_dim.\n",
        "\n",
        "Let's see it in action."
      ],
      "metadata": {
        "id": "yV2LBRQag4k2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras  import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim = len(rct_20k_text_vocab), #set input length\n",
        "                             output_dim = 128, #output shape\n",
        "                             mask_zero=True, # use masking to handle variable sequence lengths(save space)\n",
        "                             input_length= 55, #how long is each input\n",
        "                             name=\"token_embedding\")\n",
        "embedding"
      ],
      "metadata": {
        "id": "WK4MZ2Pys2BK",
        "outputId": "b116ae24-c0e0-4207-cde8-3d3043f504d7",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:22:28.201037Z",
          "iopub.execute_input": "2023-08-05T05:22:28.201598Z",
          "iopub.status.idle": "2023-08-05T05:22:28.211644Z",
          "shell.execute_reply.started": "2023-08-05T05:22:28.201561Z",
          "shell.execute_reply": "2023-08-05T05:22:28.210484Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.layers.core.embedding.Embedding at 0x78b35e18a080>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show example embedding\n",
        "print(f\"Sentence before vectorization: \\n {target_sentence}\\n\")\n",
        "vectorized_sentence = text_vectorizer([target_sentence])\n",
        "print(f\"Sentence after vectorization (before embedding): \\n {vectorized_sentence}\\n\")\n",
        "embedded_sentence = embedding(vectorized_sentence)\n",
        "print(f\"Sentence after embedding: \\n {embedded_sentence}\\n\")\n",
        "print(f\"Embedded sentence shape: {embedded_sentence.shape}\")"
      ],
      "metadata": {
        "id": "U54ulxt9gyXC",
        "outputId": "ea5b3dba-1f61-44e1-d3ca-9d00130f2d57",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:22:28.213267Z",
          "iopub.execute_input": "2023-08-05T05:22:28.213678Z",
          "iopub.status.idle": "2023-08-05T05:22:28.271769Z",
          "shell.execute_reply.started": "2023-08-05T05:22:28.213644Z",
          "shell.execute_reply": "2023-08-05T05:22:28.270646Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence before vectorization: \n",
            " recent symptoms stand as a major determinant of stroke risk in patients with carotid stenosis , likely reflective of atherosclerotic plaque destabilization .\n",
            "\n",
            "Sentence after vectorization (before embedding): \n",
            " [[  968   144  7008    25     8   347  6417     4   276    73     5    12\n",
            "      7  1839  1484   532  7996     4  5457  1072 17308     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0]]\n",
            "\n",
            "Sentence after embedding: \n",
            " [[[ 0.03838983 -0.01853728 -0.03442228 ...  0.04810632 -0.00823007\n",
            "    0.03244697]\n",
            "  [ 0.01145483  0.03878272 -0.01417998 ...  0.03004653 -0.04092328\n",
            "   -0.04843861]\n",
            "  [-0.03454005 -0.02721649  0.00252215 ...  0.03820414 -0.03793504\n",
            "   -0.02327253]\n",
            "  ...\n",
            "  [ 0.04485999 -0.00817966 -0.03765669 ... -0.03283616  0.02101305\n",
            "    0.04486391]\n",
            "  [ 0.04485999 -0.00817966 -0.03765669 ... -0.03283616  0.02101305\n",
            "    0.04486391]\n",
            "  [ 0.04485999 -0.00817966 -0.03765669 ... -0.03283616  0.02101305\n",
            "    0.04486391]]]\n",
            "\n",
            "Embedded sentence shape: (1, 55, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating datasets (making sure our data loads as fast as possible)\n",
        "\n"
      ],
      "metadata": {
        "id": "vfalNMQyj-1a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've gone through all the trouble of preprocessing our datasets to be used with a machine learning model, however, there are still a few steps we can use to make them work faster with our models.\n",
        "\n",
        "Namely, the `tf.data `API provides methods which enable faster data loading."
      ],
      "metadata": {
        "id": "bi78ajtkerBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn our data into TensorFlow Datasets\n",
        "train_dataset =  tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "id": "VJExrMi-lGlj",
        "outputId": "7f2f61b4-a7cd-4563-f4cf-27ccb0b1f593",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:22:28.273986Z",
          "iopub.execute_input": "2023-08-05T05:22:28.275088Z",
          "iopub.status.idle": "2023-08-05T05:22:29.257240Z",
          "shell.execute_reply.started": "2023-08-05T05:22:28.275052Z",
          "shell.execute_reply": "2023-08-05T05:22:29.256204Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take the TensorSliceDataset's and turn them into prefetch dataset\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "koNe9Uu7mm7q",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:22:29.258690Z",
          "iopub.execute_input": "2023-08-05T05:22:29.259037Z",
          "iopub.status.idle": "2023-08-05T05:22:29.272464Z",
          "shell.execute_reply.started": "2023-08-05T05:22:29.259008Z",
          "shell.execute_reply": "2023-08-05T05:22:29.271532Z"
        },
        "trusted": true
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "id": "prsjkHlLnuC7",
        "outputId": "ade8c2a9-2c2e-4c60-e0c7-99c1539509cf",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:22:29.275224Z",
          "iopub.execute_input": "2023-08-05T05:22:29.276121Z",
          "iopub.status.idle": "2023-08-05T05:22:29.283623Z",
          "shell.execute_reply.started": "2023-08-05T05:22:29.276087Z",
          "shell.execute_reply": "2023-08-05T05:22:29.282644Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1: Conv1D with token embeddings"
      ],
      "metadata": {
        "id": "zgDJ3xlfn1O-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alright, we've now got a way to numerically represent our text and labels, time to build a series of deep models to try and improve upon our baseline.\n",
        "\n",
        "All of our deep models will follow a similar structure:\n",
        "\n",
        "> Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)\n",
        "\n",
        "The main component we'll be changing throughout is the Layers component. Because any modern deep NLP model requires text to be converted into an embedding before meaningful patterns can be discovered within.\n",
        "\n",
        "The first model we're going to build is a 1-dimensional Convolutional Neural Network.\n",
        "\n",
        "We're also going to be following the standard machine learning workflow of:\n",
        "\n",
        " * Build model\n",
        " * Train model\n",
        " * Evaluate model (make predictions and compare to ground truth)\n"
      ],
      "metadata": {
        "id": "ZxBvxDDBew2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "# Build the model\n",
        "inputs = layers.Input(shape=(1, ), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(filters=64, kernel_size=5,  activation=\"relu\", padding =\"same\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(5, activation=\"softmax\")(x)\n",
        "\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_Conv1D\")\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "                metrics=[\"accuracy\"],\n",
        "                optimizer=tf.keras.optimizers.Adam())"
      ],
      "metadata": {
        "id": "K1Kk3piaoQH8",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:22:29.285464Z",
          "iopub.execute_input": "2023-08-05T05:22:29.285724Z",
          "iopub.status.idle": "2023-08-05T05:22:29.384138Z",
          "shell.execute_reply.started": "2023-08-05T05:22:29.285701Z",
          "shell.execute_reply": "2023-08-05T05:22:29.383106Z"
        },
        "trusted": true
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "id": "cfpTIe5Mp0cQ",
        "outputId": "c0d88559-a707-4289-b63a-e2ce708faf2f",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:22:29.386236Z",
          "iopub.execute_input": "2023-08-05T05:22:29.386819Z",
          "iopub.status.idle": "2023-08-05T05:22:29.413897Z",
          "shell.execute_reply.started": "2023-08-05T05:22:29.386773Z",
          "shell.execute_reply": "2023-08-05T05:22:29.413099Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_Conv1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (Text  (None, 55)                0         \n",
            " Vectorization)                                                  \n",
            "                                                                 \n",
            " token_embedding (Embedding  (None, 55, 128)           8299648   \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 55, 64)            41024     \n",
            "                                                                 \n",
            " global_max_pooling1d (Glob  (None, 64)                0         \n",
            " alMaxPooling1D)                                                 \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8340997 (31.82 MB)\n",
            "Trainable params: 8340997 (31.82 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wonderful! We've got our first deep sequence model built and ready to go.\n",
        "\n",
        "Checking out the model summary, you'll notice the majority of the trainable parameters are within the embedding layer. If we were to increase the size of the embedding (by increasing the `output_dim `parameter of the` Embedding` layer), the number of trainable parameters would increase dramatically.\n",
        "\n",
        "It's time to fit our model to the training data but we're going to make a mindful change.\n",
        "\n",
        "Since our training data contains nearly 200,000 sentences, fitting a deep model may take a while even with a GPU. So to keep our experiments swift, we're going to run them on a subset of the training dataset.\n",
        "\n",
        "More specifically, we'll only use the first 10% of batches (about 18,000 samples) of the training set to train on and the first 10% of batches from the validation set to validate on."
      ],
      "metadata": {
        "id": "lJs-0D0NfNwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_model_1 = model_1.fit(train_dataset,\n",
        "                              validation_data=(valid_dataset),\n",
        "                              epochs=3,\n",
        "                              steps_per_epoch=int(0.1 * len(train_dataset)),\n",
        "                              validation_steps=int(len(valid_dataset) * 0.10))"
      ],
      "metadata": {
        "id": "whrL8CMxp4rS",
        "outputId": "8271e295-bbbb-4552-d58a-b76eb596cf93",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:22:29.414879Z",
          "iopub.execute_input": "2023-08-05T05:22:29.415413Z",
          "iopub.status.idle": "2023-08-05T05:23:52.118915Z",
          "shell.execute_reply.started": "2023-08-05T05:22:29.415385Z",
          "shell.execute_reply": "2023-08-05T05:23:52.117759Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 66s 115ms/step - loss: 0.8351 - accuracy: 0.6839 - val_loss: 0.5846 - val_accuracy: 0.7822\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 65s 115ms/step - loss: 0.5799 - accuracy: 0.7874 - val_loss: 0.5404 - val_accuracy: 0.8009\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 65s 116ms/step - loss: 0.5418 - accuracy: 0.8005 - val_loss: 0.5134 - val_accuracy: 0.8191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Brilliant! We've got our first trained deep sequence model, and it didn't take too long (and if we didn't prefetch our batched data, it would've taken longer).\n",
        "\n",
        "Time to make some predictions with our model and then evaluate them."
      ],
      "metadata": {
        "id": "ThZl2mFLfXcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on validation data\n",
        "model_1.evaluate(valid_dataset)"
      ],
      "metadata": {
        "id": "_6rig1r7qUrC",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:23:52.120809Z",
          "iopub.execute_input": "2023-08-05T05:23:52.121207Z",
          "iopub.status.idle": "2023-08-05T05:23:57.243212Z",
          "shell.execute_reply.started": "2023-08-05T05:23:52.121151Z",
          "shell.execute_reply": "2023-08-05T05:23:57.242211Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction(model_predicts prediction probabilities for each class)\n",
        "model_1_pred_probs =  model_1.predict(valid_dataset)\n",
        "model_1_preds = tf.argmax(model_1_pred_probs, axis=1)\n",
        "model_1_preds"
      ],
      "metadata": {
        "id": "C2RKM635tJav",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:23:57.244890Z",
          "iopub.execute_input": "2023-08-05T05:23:57.245278Z",
          "iopub.status.idle": "2023-08-05T05:24:00.157362Z",
          "shell.execute_reply.started": "2023-08-05T05:23:57.245235Z",
          "shell.execute_reply": "2023-08-05T05:24:00.156162Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_preds[:10]"
      ],
      "metadata": {
        "id": "LOT23cHzt3fY",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:24:00.158741Z",
          "iopub.execute_input": "2023-08-05T05:24:00.159153Z",
          "iopub.status.idle": "2023-08-05T05:24:00.170478Z",
          "shell.execute_reply.started": "2023-08-05T05:24:00.159113Z",
          "shell.execute_reply": "2023-08-05T05:24:00.169246Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_1 results\n",
        "model_1_results= calculate_results(y_pred=model_1_preds,\n",
        "                                   y_true=val_labels_encoded)"
      ],
      "metadata": {
        "id": "1PAvSKkiuBOq",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:24:00.172573Z",
          "iopub.execute_input": "2023-08-05T05:24:00.172875Z",
          "iopub.status.idle": "2023-08-05T05:24:00.194538Z",
          "shell.execute_reply.started": "2023-08-05T05:24:00.172839Z",
          "shell.execute_reply": "2023-08-05T05:24:00.193602Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results, baseline_results\n"
      ],
      "metadata": {
        "id": "R1YN-R1GuTxi",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:24:00.195830Z",
          "iopub.execute_input": "2023-08-05T05:24:00.196286Z",
          "iopub.status.idle": "2023-08-05T05:24:00.204335Z",
          "shell.execute_reply.started": "2023-08-05T05:24:00.196249Z",
          "shell.execute_reply": "2023-08-05T05:24:00.203225Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2: Feature extraction with pretrained  token embedding\n",
        "Now let's use pretrained word embeddings from TensorFlow Hub, more specifically the universal sentence encoder: https://tfhub.dev/google/universal-sentence-encoder/4\n",
        "\n",
        "The model structure will look like:\n",
        "\n",
        "> Inputs (string) -> Pretrained embeddings from TensorFlow Hub (Universal Sentence Encoder) -> Layers -> Output (prediction probabilities)\n",
        "\n",
        "You'll notice the lack of tokenization layer we've used in a previous model. This is because the Universal Sentence Encoder (USE) takes care of tokenization for us.\n",
        "\n",
        "This type of model is called transfer learning, or more specifically, **feature extraction transfer learning**. In other words, taking the patterns a model has learned elsewhere and applying it to our own problem."
      ],
      "metadata": {
        "id": "eKjNnYbnurgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "# Create a Keras layer using the USE pretrained layer from tensorflowhub\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\",\n",
        "                                        input_shape=[],\n",
        "                                        dtype=tf.string,\n",
        "                                        trainable= False,\n",
        "                                        name=\"USE-large\")"
      ],
      "metadata": {
        "id": "wcbiupCYvrlq",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:24:00.206012Z",
          "iopub.execute_input": "2023-08-05T05:24:00.206758Z",
          "iopub.status.idle": "2023-08-05T05:24:21.196144Z",
          "shell.execute_reply.started": "2023-08-05T05:24:00.206721Z",
          "shell.execute_reply": "2023-08-05T05:24:21.195115Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out the embedding on a random sentence\n",
        "random_training_sentence = random.choice(train_sentences)\n",
        "print(f\"Random training sentence:\\n{random_training_sentence}\\n\")\n",
        "use_embedded_sentence = tf_hub_embedding_layer([random_training_sentence])\n",
        "print(f\"Sentence after embedding:\\n{use_embedded_sentence[0][:30]} (truncated output)...\\n\")\n",
        "print(f\"Length of sentence embedding:\\n{len(use_embedded_sentence[0])}\")\n",
        ""
      ],
      "metadata": {
        "id": "pO249uC_f4ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model\n",
        "model_2 = tf.keras.Sequential([\n",
        "    sentence_encoder_layer,\n",
        "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(5, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model_2.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=\"adam\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_2.summary()"
      ],
      "metadata": {
        "id": "QaXFdO2PxpV8",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:24:21.197481Z",
          "iopub.execute_input": "2023-08-05T05:24:21.197842Z",
          "iopub.status.idle": "2023-08-05T05:24:24.188512Z",
          "shell.execute_reply.started": "2023-08-05T05:24:21.197809Z",
          "shell.execute_reply": "2023-08-05T05:24:24.187513Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_model_2 = model_2.fit(train_dataset,\n",
        "                              epochs=3,\n",
        "                              validation_data=(valid_dataset),\n",
        "                              steps_per_epoch=int(0.1 * len(train_dataset)),\n",
        "                              validation_steps=int(0.1 * len(valid_dataset)))"
      ],
      "metadata": {
        "id": "051sf8G5yk3L",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:24:24.190132Z",
          "iopub.execute_input": "2023-08-05T05:24:24.190995Z",
          "iopub.status.idle": "2023-08-05T05:27:15.139889Z",
          "shell.execute_reply.started": "2023-08-05T05:24:24.190958Z",
          "shell.execute_reply": "2023-08-05T05:27:15.138780Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.evaluate(valid_dataset)"
      ],
      "metadata": {
        "id": "dW_MGxoUzZ11",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:27:15.141589Z",
          "iopub.execute_input": "2023-08-05T05:27:15.142063Z",
          "iopub.status.idle": "2023-08-05T05:27:59.631248Z",
          "shell.execute_reply.started": "2023-08-05T05:27:15.142024Z",
          "shell.execute_reply": "2023-08-05T05:27:59.630090Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with feature extraction model\n",
        "model_2_pred_probs = model_2.predict(valid_dataset)\n",
        "model_2_preds = tf.argmax(model_2_pred_probs, axis=1)\n",
        "model_2_preds[:10]"
      ],
      "metadata": {
        "id": "Q5DRSV5U1SbA",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:27:59.633038Z",
          "iopub.execute_input": "2023-08-05T05:27:59.633461Z",
          "iopub.status.idle": "2023-08-05T05:28:53.288237Z",
          "shell.execute_reply.started": "2023-08-05T05:27:59.633422Z",
          "shell.execute_reply": "2023-08-05T05:28:53.287117Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calulate results Tfhub pretrained embeddings results on val set\n",
        "model_2_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "metadata": {
        "id": "ezVcHm-d1256",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:28:53.289759Z",
          "iopub.execute_input": "2023-08-05T05:28:53.290238Z",
          "iopub.status.idle": "2023-08-05T05:28:53.314495Z",
          "shell.execute_reply.started": "2023-08-05T05:28:53.290203Z",
          "shell.execute_reply": "2023-08-05T05:28:53.313380Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3: Conv1D with character embeddings\n",
        "The paper which we're replicating states they used a combination of token and character-level embeddings.\n",
        "\n",
        "Previously we've token-level embeddings but we'll need to do similar steps for characters if we want to use char-level embeddings."
      ],
      "metadata": {
        "id": "vaLKzFUR2OsD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a character-level tokenizer"
      ],
      "metadata": {
        "id": "cDGRSVWV3Vos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences[:5]"
      ],
      "metadata": {
        "id": "1kccHy5V38bs",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:28:53.315969Z",
          "iopub.execute_input": "2023-08-05T05:28:53.317425Z",
          "iopub.status.idle": "2023-08-05T05:28:53.324519Z",
          "shell.execute_reply.started": "2023-08-05T05:28:53.317388Z",
          "shell.execute_reply": "2023-08-05T05:28:53.323394Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make function to split sentences into characters\n",
        "def split_chars(text):\n",
        "  return \" \".join(list(text))"
      ],
      "metadata": {
        "id": "ymeNfv9p3_SS",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:28:53.326113Z",
          "iopub.execute_input": "2023-08-05T05:28:53.326478Z",
          "iopub.status.idle": "2023-08-05T05:28:53.333955Z",
          "shell.execute_reply.started": "2023-08-05T05:28:53.326444Z",
          "shell.execute_reply": "2023-08-05T05:28:53.333005Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! Looks like our character-splitting function works. Let's create character-level datasets by splitting our sequence datasets into characters."
      ],
      "metadata": {
        "id": "Td-iD4HSgMX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Text splitting non-character-level sequence into characters\n",
        "split_chars(train_sentences[0])"
      ],
      "metadata": {
        "id": "Kwsamyuo4ZDk",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:28:53.335445Z",
          "iopub.execute_input": "2023-08-05T05:28:53.335784Z",
          "iopub.status.idle": "2023-08-05T05:28:53.345440Z",
          "shell.execute_reply.started": "2023-08-05T05:28:53.335750Z",
          "shell.execute_reply": "2023-08-05T05:28:53.344292Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split sequence level data splits into character level data splits\n",
        "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
        "valid_chars = [split_chars(sentence) for sentence in val_sentences]\n",
        "test_chars = [split_chars(sentence)for sentence in test_sentences]\n",
        "train_chars[:5]"
      ],
      "metadata": {
        "id": "23igsHUq4sys",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:28:53.346935Z",
          "iopub.execute_input": "2023-08-05T05:28:53.347447Z",
          "iopub.status.idle": "2023-08-05T05:28:55.070307Z",
          "shell.execute_reply.started": "2023-08-05T05:28:53.347414Z",
          "shell.execute_reply": "2023-08-05T05:28:55.069141Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What's the average character length?\n",
        "chars_length = [len(sentence) for sentence in train_sentences]\n",
        "mean_char_len = np.mean(chars_length)\n",
        "mean_char_len"
      ],
      "metadata": {
        "id": "LwSEt_XC5b9O",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:28:55.071619Z",
          "iopub.execute_input": "2023-08-05T05:28:55.072059Z",
          "iopub.status.idle": "2023-08-05T05:28:55.136531Z",
          "shell.execute_reply.started": "2023-08-05T05:28:55.072024Z",
          "shell.execute_reply": "2023-08-05T05:28:55.135473Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the distribution of our sentence ar a character level\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(chars_length, bins=7)"
      ],
      "metadata": {
        "id": "n5c60iwn5xYb",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:28:55.138235Z",
          "iopub.execute_input": "2023-08-05T05:28:55.138584Z",
          "iopub.status.idle": "2023-08-05T05:28:56.269210Z",
          "shell.execute_reply.started": "2023-08-05T05:28:55.138551Z",
          "shell.execute_reply": "2023-08-05T05:28:56.268115Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find what character length cover 95% of sequences\n",
        "output_seq_char_len = int(np.percentile(chars_length, 95))\n",
        "output_seq_char_len"
      ],
      "metadata": {
        "id": "Az8iV4U76BgV",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:28:56.270770Z",
          "iopub.execute_input": "2023-08-05T05:28:56.271117Z",
          "iopub.status.idle": "2023-08-05T05:28:56.303051Z",
          "shell.execute_reply.started": "2023-08-05T05:28:56.271084Z",
          "shell.execute_reply": "2023-08-05T05:28:56.301979Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all keyboard characters\n",
        "import string\n",
        "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
        "print(len(alphabet), alphabet)"
      ],
      "metadata": {
        "id": "puvcSSfJ6Yh0",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:28:56.304489Z",
          "iopub.execute_input": "2023-08-05T05:28:56.304916Z",
          "iopub.status.idle": "2023-08-05T05:28:56.323392Z",
          "shell.execute_reply.started": "2023-08-05T05:28:56.304882Z",
          "shell.execute_reply": "2023-08-05T05:28:56.322104Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create char-level tokenvectorier instance\n",
        "NUM_CHAR_TOKENS = len(alphabet) + 2 #add 3 for space and OOV token(OOV = out of vocab)\n",
        "char_vectorizer = TextVectorization(max_tokens=NUM_CHAR_TOKENS,\n",
        "                                    output_sequence_length = output_seq_char_len,\n",
        "                                    # standardize=None,\n",
        "                                    name=\"char_vectorizer\")"
      ],
      "metadata": {
        "id": "zYMkWNaB7euU",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:28:56.324951Z",
          "iopub.execute_input": "2023-08-05T05:28:56.325337Z",
          "iopub.status.idle": "2023-08-05T05:28:56.339139Z",
          "shell.execute_reply.started": "2023-08-05T05:28:56.325303Z",
          "shell.execute_reply": "2023-08-05T05:28:56.338209Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapt to training chars\n",
        "char_vectorizer.adapt(train_chars)"
      ],
      "metadata": {
        "id": "KNf9F-IO8lU_",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:28:56.340697Z",
          "iopub.execute_input": "2023-08-05T05:28:56.341093Z",
          "iopub.status.idle": "2023-08-05T05:29:19.982800Z",
          "shell.execute_reply.started": "2023-08-05T05:28:56.341034Z",
          "shell.execute_reply": "2023-08-05T05:29:19.981771Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check character vocab stats\n",
        "char_vocab = char_vectorizer.get_vocabulary()\n",
        "print(f\"Number of different characters in character vocab: {len(char_vocab)}\")\n",
        "print(f\"5 Most common characters: {char_vocab[:5]}\")\n",
        "print(f\"5 least common characters: {char_vocab[-5:]}\")"
      ],
      "metadata": {
        "id": "2-aQV3A98tPD",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:29:19.984868Z",
          "iopub.execute_input": "2023-08-05T05:29:19.985278Z",
          "iopub.status.idle": "2023-08-05T05:29:19.992838Z",
          "shell.execute_reply.started": "2023-08-05T05:29:19.985232Z",
          "shell.execute_reply": "2023-08-05T05:29:19.991903Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out character vectorizer\n",
        "random_train_chars = random.choice(train_chars)\n",
        "print(f\"Charified text:\\n {random_train_chars}\")\n",
        "print(f\"\\nLength of random_train_chars: {len(random_train_chars.split())}\")\n",
        "vectorized_chars = char_vectorizer([random_train_chars])\n",
        "print(f\"\\nVectorized chars:\\n {vectorized_chars}\")\n",
        "print(f\"\\nLength of Vectorized chars: {len(vectorized_chars[0])}\")"
      ],
      "metadata": {
        "id": "ZEaitie49gvV",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:29:19.994057Z",
          "iopub.execute_input": "2023-08-05T05:29:19.994976Z",
          "iopub.status.idle": "2023-08-05T05:29:20.018631Z",
          "shell.execute_reply.started": "2023-08-05T05:29:19.994940Z",
          "shell.execute_reply": "2023-08-05T05:29:20.017666Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a  Character level embedding\n",
        "We've got a way to vectorize our character-level sequences, now's time to create a character-level embedding.\n",
        "\n",
        "Just like our custom token embedding, we can do so using the `tensorflow.keras.layers.Embedding class.`\n",
        "\n",
        "Our character-level embedding layer requires an input dimension and output dimension."
      ],
      "metadata": {
        "id": "brZtkVFNkXgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "char_embedding = layers.Embedding(input_dim = len(char_vocab),\n",
        "                                  output_dim = 25, #this is size of the char embed in paper\n",
        "                                  mask_zero=True,\n",
        "                                  name = \"character_embedding\")"
      ],
      "metadata": {
        "id": "YRfa-KCblFKh",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:29:20.020469Z",
          "iopub.execute_input": "2023-08-05T05:29:20.020755Z",
          "iopub.status.idle": "2023-08-05T05:29:20.026645Z",
          "shell.execute_reply.started": "2023-08-05T05:29:20.020731Z",
          "shell.execute_reply": "2023-08-05T05:29:20.025643Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show sample char embedding\n",
        "print(f\"Sentence before vectorization: \\n {random_train_chars}\\n\")\n",
        "vectorized_chars = char_vectorizer([random_train_chars])\n",
        "print(f\"Sentence after vectorization(before embedding):\\n {vectorized_chars}\\n\")\n",
        "char_embedded = char_embedding(vectorized_chars)\n",
        "print(f\"Sentence after embedding:\\n{char_embedded}\\n\")\n",
        "print(f\"Embedded char sentence shape:{char_embedded.shape}\")"
      ],
      "metadata": {
        "id": "YFCfkpfWkn6H",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:29:20.028027Z",
          "iopub.execute_input": "2023-08-05T05:29:20.028605Z",
          "iopub.status.idle": "2023-08-05T05:29:20.058304Z",
          "shell.execute_reply.started": "2023-08-05T05:29:20.028571Z",
          "shell.execute_reply": "2023-08-05T05:29:20.057236Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a Conv1D model to fit on character embeddings"
      ],
      "metadata": {
        "id": "Yqu6mnusnGWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make Conv1D on char embedding\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "char_vectors = char_vectorizer(inputs)\n",
        "char_embeddings = char_embedding(char_vectors)\n",
        "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(char_embeddings)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "model_3 = tf.keras.Model(inputs=inputs,\n",
        "                         outputs=outputs,\n",
        "                         name=\"model_3_conv1D_char_embedding\")\n",
        "\n",
        "# Compile model\n",
        "model_3.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "hfL2H1cpoyAH",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:29:20.060161Z",
          "iopub.execute_input": "2023-08-05T05:29:20.060832Z",
          "iopub.status.idle": "2023-08-05T05:29:20.154950Z",
          "shell.execute_reply.started": "2023-08-05T05:29:20.060793Z",
          "shell.execute_reply": "2023-08-05T05:29:20.154147Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.summary()"
      ],
      "metadata": {
        "id": "Q_ZQ2NygqeN4",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:29:20.156014Z",
          "iopub.execute_input": "2023-08-05T05:29:20.156352Z",
          "iopub.status.idle": "2023-08-05T05:29:20.176565Z",
          "shell.execute_reply.started": "2023-08-05T05:29:20.156318Z",
          "shell.execute_reply": "2023-08-05T05:29:20.175478Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create char level datasets\n",
        "train_char_dataset = tf.data.Dataset.from_tensor_slices((train_chars, train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_char_dataset = tf.data.Dataset.from_tensor_slices((valid_chars, val_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_char_dataset = tf.data.Dataset.from_tensor_slices((test_chars, test_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "ttK7u-LdskKC",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:29:20.178153Z",
          "iopub.execute_input": "2023-08-05T05:29:20.178761Z",
          "iopub.status.idle": "2023-08-05T05:29:21.368498Z",
          "shell.execute_reply.started": "2023-08-05T05:29:20.178725Z",
          "shell.execute_reply": "2023-08-05T05:29:21.367458Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_model_3 = model_3.fit(train_char_dataset,\n",
        "                              steps_per_epoch = int(0.1 * len(train_char_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=val_char_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_char_dataset)))"
      ],
      "metadata": {
        "id": "Kz13WaSit8gW",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:29:21.370098Z",
          "iopub.execute_input": "2023-08-05T05:29:21.370486Z",
          "iopub.status.idle": "2023-08-05T05:29:33.424656Z",
          "shell.execute_reply.started": "2023-08-05T05:29:21.370450Z",
          "shell.execute_reply": "2023-08-05T05:29:33.423625Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction character model\n",
        "model_3_pred_probs = model_3.predict(val_char_dataset)\n",
        "model_3_preds = tf.argmax(model_3_pred_probs, axis=1)"
      ],
      "metadata": {
        "id": "84An6eW0ulIg",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:29:33.426279Z",
          "iopub.execute_input": "2023-08-05T05:29:33.426676Z",
          "iopub.status.idle": "2023-08-05T05:29:36.386229Z",
          "shell.execute_reply.started": "2023-08-05T05:29:33.426640Z",
          "shell.execute_reply": "2023-08-05T05:29:36.385150Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate results foe connv1d model\n",
        "model_3_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred= model_3_preds)"
      ],
      "metadata": {
        "id": "A_XjcDoUvKZR",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:29:36.387901Z",
          "iopub.execute_input": "2023-08-05T05:29:36.388278Z",
          "iopub.status.idle": "2023-08-05T05:29:36.408022Z",
          "shell.execute_reply.started": "2023-08-05T05:29:36.388242Z",
          "shell.execute_reply": "2023-08-05T05:29:36.407037Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_results"
      ],
      "metadata": {
        "id": "4h620GxzvfbV",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:29:36.409435Z",
          "iopub.execute_input": "2023-08-05T05:29:36.410044Z",
          "iopub.status.idle": "2023-08-05T05:29:36.416655Z",
          "shell.execute_reply.started": "2023-08-05T05:29:36.410009Z",
          "shell.execute_reply": "2023-08-05T05:29:36.415577Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 4: Combining pretrained token embeddings + character embeddings(hybrid embedding layer)\n",
        "\n",
        "1. Create a token-level embedding(similar `model_1`)\n",
        "2. Create a character-level model(similar to `model_3` with slight modification)\n",
        "3. Combine 1 & 2 with concatenate(`layers.Concatenate`)\n",
        "4. Build a series of output layers on top of 3 similar to Figure 1 and section 4.2 of https://arxiv.org/pdf/1612.05251.pdf\n",
        "5. Construct a model which takes token and character-level sequences as input and produces sequence label probabilities as output"
      ],
      "metadata": {
        "id": "0QR_fpvFvhOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Setup token inputs/model\n",
        "token_inputs = layers.Input(shape=[], dtype=tf.string, name=\"token_input\")\n",
        "token_embeddings = sentence_encoder_layer(token_inputs)\n",
        "token_outputs = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
        "token_model = tf.keras.Model(inputs=token_inputs,\n",
        "                             outputs=token_outputs)\n",
        "\n",
        "# 2. Setup char inputs/model\n",
        "char_inputs = layers.Input(shape=(1,), dtype=tf.string, name=\"char_input\")\n",
        "char_vectors = char_vectorizer(char_inputs)\n",
        "char_embeddings = char_embedding(char_vectors)\n",
        "char_bi_lstm= layers.Bidirectional(layers.LSTM(24))(char_embeddings)\n",
        "char_model = tf.keras.Model(inputs=char_inputs,\n",
        "                            outputs=char_bi_lstm)\n",
        "\n",
        "# 3. Concatenate token and char inputs(create hybrid token embedding)\n",
        "token_char_concat = layers.Concatenate(name=\"token_char_hybrid\")([token_model.output,\n",
        "                                                                  char_model.output])\n",
        "\n",
        "# 4. Create output layers - adding in Dropout in section of paper\n",
        "combined_dropout = layers.Dropout(0.5)(token_char_concat)\n",
        "combined_dense = layers.Dense(128, activation=\"relu\")(combined_dropout)\n",
        "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
        "output_layer = layers.Dense(num_classes, activation=\"softmax\")(final_dropout)\n",
        "\n",
        "# 5. Construct model with char and token inputs\n",
        "model_4 = tf.keras.Model(inputs=[token_model.input, char_model.input],\n",
        "                         outputs=output_layer)\n"
      ],
      "metadata": {
        "id": "T7nW50pAyK5p",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:29:36.418050Z",
          "iopub.execute_input": "2023-08-05T05:29:36.418952Z",
          "iopub.status.idle": "2023-08-05T05:29:39.871721Z",
          "shell.execute_reply.started": "2023-08-05T05:29:36.418915Z",
          "shell.execute_reply": "2023-08-05T05:29:39.870678Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get summary\n",
        "model_4.summary()"
      ],
      "metadata": {
        "id": "LThYBeB_4g-F",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:29:39.873030Z",
          "iopub.execute_input": "2023-08-05T05:29:39.873388Z",
          "iopub.status.idle": "2023-08-05T05:29:39.992990Z",
          "shell.execute_reply.started": "2023-08-05T05:29:39.873353Z",
          "shell.execute_reply": "2023-08-05T05:29:39.992020Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot hybrid token and character model\n",
        "from keras.utils import plot_model\n",
        "plot_model(model_4, show_shapes=True)"
      ],
      "metadata": {
        "id": "B-jM8hWa49J8",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:29:39.994498Z",
          "iopub.execute_input": "2023-08-05T05:29:39.995090Z",
          "iopub.status.idle": "2023-08-05T05:29:40.321238Z",
          "shell.execute_reply.started": "2023-08-05T05:29:39.995053Z",
          "shell.execute_reply": "2023-08-05T05:29:40.320274Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile token char model\n",
        "model_4.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=\"adam\",\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "jDpSQCqj5wd0",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:29:40.322633Z",
          "iopub.execute_input": "2023-08-05T05:29:40.323002Z",
          "iopub.status.idle": "2023-08-05T05:29:40.338836Z",
          "shell.execute_reply.started": "2023-08-05T05:29:40.322967Z",
          "shell.execute_reply": "2023-08-05T05:29:40.337501Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combining token and character data into a tf.data Dataset"
      ],
      "metadata": {
        "id": "trIKs9KF2oYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine chars and tokens into a dataset\n",
        "train_char_token_data = tf.data.Dataset.from_tensor_slices((train_sentences,train_chars))\n",
        "train_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot)\n",
        "train_char_token_dataset = tf.data.Dataset.zip((train_char_token_data, train_char_token_labels))\n",
        "\n",
        "# Prefetch and batch train data\n",
        "train_char_token_dataset = train_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "NX783YkC3J4l",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:29:40.340922Z",
          "iopub.execute_input": "2023-08-05T05:29:40.341848Z",
          "iopub.status.idle": "2023-08-05T05:29:41.951882Z",
          "shell.execute_reply.started": "2023-08-05T05:29:40.341814Z",
          "shell.execute_reply": "2023-08-05T05:29:41.950863Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine chars and tokens into a dataset\n",
        "val_char_token_data = tf.data.Dataset.from_tensor_slices((val_sentences,valid_chars))\n",
        "val_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
        "val_char_token_dataset = tf.data.Dataset.zip((val_char_token_data, val_char_token_labels))\n",
        "\n",
        "# Prefetch and batch val data\n",
        "val_char_token_dataset = val_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "2Q0TXimH40Go",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:29:41.953200Z",
          "iopub.execute_input": "2023-08-05T05:29:41.953551Z",
          "iopub.status.idle": "2023-08-05T05:29:42.256976Z",
          "shell.execute_reply.started": "2023-08-05T05:29:41.953518Z",
          "shell.execute_reply": "2023-08-05T05:29:42.255994Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out training char and token embedding dataset\n",
        "train_char_token_dataset, val_char_token_dataset"
      ],
      "metadata": {
        "id": "Fxy5F_0K5HUu",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:29:42.258225Z",
          "iopub.execute_input": "2023-08-05T05:29:42.258579Z",
          "iopub.status.idle": "2023-08-05T05:29:42.265199Z",
          "shell.execute_reply.started": "2023-08-05T05:29:42.258544Z",
          "shell.execute_reply": "2023-08-05T05:29:42.264036Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fitting a model on token and character-level sequences"
      ],
      "metadata": {
        "id": "zE-P8nlE5kRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model on tokens and chars\n",
        "history_model_4 = model_4.fit(train_char_token_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_char_token_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=val_char_token_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_char_token_dataset)))"
      ],
      "metadata": {
        "id": "uQPB3MJv6J3e",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:29:42.266809Z",
          "iopub.execute_input": "2023-08-05T05:29:42.267758Z",
          "iopub.status.idle": "2023-08-05T05:33:20.154521Z",
          "shell.execute_reply.started": "2023-08-05T05:29:42.267722Z",
          "shell.execute_reply": "2023-08-05T05:33:20.153065Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model\n",
        "model_4.evaluate(val_char_token_dataset)"
      ],
      "metadata": {
        "id": "UYDrpAk762tr",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:33:20.156050Z",
          "iopub.execute_input": "2023-08-05T05:33:20.156378Z",
          "iopub.status.idle": "2023-08-05T05:34:16.662225Z",
          "shell.execute_reply.started": "2023-08-05T05:33:20.156350Z",
          "shell.execute_reply": "2023-08-05T05:34:16.661108Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predictions\n",
        "model_4_preds_probs = model_4.predict(val_char_token_dataset)"
      ],
      "metadata": {
        "id": "f4mSgFBo6Amu",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:34:16.663978Z",
          "iopub.execute_input": "2023-08-05T05:34:16.664347Z",
          "iopub.status.idle": "2023-08-05T05:35:15.935630Z",
          "shell.execute_reply.started": "2023-08-05T05:34:16.664307Z",
          "shell.execute_reply": "2023-08-05T05:35:15.934446Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Round the preds\n",
        "preds_model_4 = tf.argmax(model_4_preds_probs, axis=1)\n",
        "preds_model_4"
      ],
      "metadata": {
        "id": "auXkgacI8rc5",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:35:15.937023Z",
          "iopub.execute_input": "2023-08-05T05:35:15.937411Z",
          "iopub.status.idle": "2023-08-05T05:35:15.950836Z",
          "shell.execute_reply.started": "2023-08-05T05:35:15.937375Z",
          "shell.execute_reply": "2023-08-05T05:35:15.949752Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calulate the evaluation matrix\n",
        "model_4_results = calculate_results(y_pred=preds_model_4,\n",
        "                                    y_true=val_labels_encoded)\n",
        "model_4_results"
      ],
      "metadata": {
        "id": "cy6L1D_S9BpL",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:35:15.952826Z",
          "iopub.execute_input": "2023-08-05T05:35:15.953244Z",
          "iopub.status.idle": "2023-08-05T05:35:15.984116Z",
          "shell.execute_reply.started": "2023-08-05T05:35:15.953185Z",
          "shell.execute_reply": "2023-08-05T05:35:15.983122Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Note**: Any engineered features used to train a model need to be available at test time. In our case, line numbers and total lines are available."
      ],
      "metadata": {
        "id": "IwGq6qcF_q9x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 5: Transfer Learning with pretrained token embeddings + character embeddings + positional embeddings"
      ],
      "metadata": {
        "id": "q9UTjiRthNFy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems like combining token embeddings and character embeddings gave our model a little performance boost.\n",
        "\n",
        "But there's one more piece of the puzzle we can add in.\n",
        "\n",
        "What if we engineered our own features into the model?\n",
        "\n",
        "Meaning, what if we took our own knowledge about the data and encoded it in a numerical way to give our model more information about our samples?\n",
        "\n",
        "The process of applying your own knowledge to build features as input to a model is called `feature engineering.`"
      ],
      "metadata": {
        "id": "IMDFjurKhYgi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create positional embeddings"
      ],
      "metadata": {
        "id": "WjPmi0K0B2gh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since our `\"line_number\" `and `\"total_line\" `columns are already numerical, we could pass them as they are to our model.\n",
        "\n",
        "But to avoid our model thinking a line with `\"line_number\"=5` is five times greater than a line with `\"line_number\"=1`, we'll use one-hot-encoding to encode our `\"line_number\"` and `\"total_lines\"` features.\n",
        "\n",
        "To do this, we can use the `tf.one_hot `utility.\n",
        "\n",
        "`tf.one_hot` returns a one-hot-encoded tensor. It accepts an array (or tensor) as input and the `depth` parameter determines the dimension of the returned tensor.\n",
        "\n",
        "To figure out what we should set the depth parameter to, let's investigate the distribution of the `\"line_number\"` column.\n",
        "\n",
        ">**ðŸ”‘ Note:**When it comes to one-hot-encoding our features, Scikit-Learn's OneHotEncoder class is another viable option here."
      ],
      "metadata": {
        "id": "79dKBHyEhc69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many different line numbers are there?\n",
        "train_df[\"line_number\"].value_counts()"
      ],
      "metadata": {
        "id": "kHCZeLFuCBfQ",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:35:15.985470Z",
          "iopub.execute_input": "2023-08-05T05:35:15.986098Z",
          "iopub.status.idle": "2023-08-05T05:35:15.998142Z",
          "shell.execute_reply.started": "2023-08-05T05:35:15.986057Z",
          "shell.execute_reply": "2023-08-05T05:35:15.997108Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the distribution of \"line_number\" column\n",
        "train_df.line_number.plot.hist()"
      ],
      "metadata": {
        "id": "EsoI4WGOCNQ_",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:35:15.999630Z",
          "iopub.execute_input": "2023-08-05T05:35:16.000222Z",
          "iopub.status.idle": "2023-08-05T05:35:16.288625Z",
          "shell.execute_reply.started": "2023-08-05T05:35:16.000187Z",
          "shell.execute_reply": "2023-08-05T05:35:16.287632Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use TensorFlow to create one-hot-encoded tensors of our \"line_number\" column\n",
        "train_line_numbers_one_hot = tf.one_hot(train_df[\"line_number\"].to_numpy(),depth=15)\n",
        "val_line_numbers_one_hot = tf.one_hot(val_df[\"line_number\"].to_numpy(),depth=15)\n",
        "test_line_numbers_one_hot = tf.one_hot(test_df[\"line_number\"].to_numpy(),depth=15)\n",
        "train_line_numbers_one_hot[:10], train_line_numbers_one_hot.shape"
      ],
      "metadata": {
        "id": "J7YNr7R-C2ps",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:35:16.300628Z",
          "iopub.execute_input": "2023-08-05T05:35:16.301445Z",
          "iopub.status.idle": "2023-08-05T05:35:16.323964Z",
          "shell.execute_reply.started": "2023-08-05T05:35:16.301415Z",
          "shell.execute_reply": "2023-08-05T05:35:16.322956Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "b00T0nSLFc_E",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:35:16.326435Z",
          "iopub.execute_input": "2023-08-05T05:35:16.327082Z",
          "iopub.status.idle": "2023-08-05T05:35:16.339633Z",
          "shell.execute_reply.started": "2023-08-05T05:35:16.327046Z",
          "shell.execute_reply": "2023-08-05T05:35:16.338328Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many total lines are there?\n",
        "train_df[\"total_lines\"].value_counts().sort_index()"
      ],
      "metadata": {
        "id": "92T1Vu3OEIq5",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:35:16.342764Z",
          "iopub.execute_input": "2023-08-05T05:35:16.343428Z",
          "iopub.status.idle": "2023-08-05T05:35:16.358349Z",
          "shell.execute_reply.started": "2023-08-05T05:35:16.343390Z",
          "shell.execute_reply": "2023-08-05T05:35:16.357412Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the distribution of \"line_number\" column\n",
        "train_df.total_lines.plot.hist()"
      ],
      "metadata": {
        "id": "mRcfH5fGFjWk",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:35:16.359770Z",
          "iopub.execute_input": "2023-08-05T05:35:16.360350Z",
          "iopub.status.idle": "2023-08-05T05:35:16.660205Z",
          "shell.execute_reply.started": "2023-08-05T05:35:16.360162Z",
          "shell.execute_reply": "2023-08-05T05:35:16.659230Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check teh coverage of a total line value of 20\n",
        "np.percentile(train_df.total_lines, 98)"
      ],
      "metadata": {
        "id": "on0ewpgmHaOj",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:35:16.661775Z",
          "iopub.execute_input": "2023-08-05T05:35:16.662453Z",
          "iopub.status.idle": "2023-08-05T05:35:16.671591Z",
          "shell.execute_reply.started": "2023-08-05T05:35:16.662412Z",
          "shell.execute_reply": "2023-08-05T05:35:16.670423Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use TensorFlow to create one-hot-encoded tensors of our \"total_lines\" column\n",
        "train_total_lines_one_hot = tf.one_hot(train_df[\"total_lines\"].to_numpy(),depth=20)\n",
        "val_total_lines_one_hot = tf.one_hot(val_df[\"total_lines\"].to_numpy(),depth=20)\n",
        "test_total_lines_one_hot = tf.one_hot(test_df[\"total_lines\"].to_numpy(),depth=20)\n",
        "train_total_lines_one_hot[:10], train_total_lines_one_hot.shape"
      ],
      "metadata": {
        "id": "sVkdQQH_GMuA",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:35:16.673531Z",
          "iopub.execute_input": "2023-08-05T05:35:16.673955Z",
          "iopub.status.idle": "2023-08-05T05:35:16.690485Z",
          "shell.execute_reply.started": "2023-08-05T05:35:16.673919Z",
          "shell.execute_reply": "2023-08-05T05:35:16.689233Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a tribrid embedding model\n",
        "\n",
        "1. Create a token-level model\n",
        "2. Create a character-level model\n",
        "3. Create a model for the \"line_number\" feature\n",
        "4. Create a model for the \"total_lines\"\n",
        "feature\n",
        "5. Combine the outputs of 1 & 2 using tf.keras.layers.Concatenate\n",
        "6. Combine the outputs of 3, 4, 5 using tf.keras.layers.Concatenate\n",
        "7. Create an output layer to accept the tribrid embedding and output label probabilities\n",
        "8. Combine the inputs of 1,2,3,4 and outputs of into a tf.keras.Model"
      ],
      "metadata": {
        "id": "_WSdeH4lGhRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Token inputs\n",
        "token_inputs = layers.Input(shape=[], dtype=\"string\", name=\"token_inputs\")\n",
        "token_embeddings = sentence_encoder_layer(token_inputs)\n",
        "token_outputs = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
        "token_model = tf.keras.Model(inputs=token_inputs,\n",
        "                             outputs=token_outputs)\n",
        "\n",
        "# 2. Char inputs\n",
        "char_inputs = layers.Input(shape=(1,), dtype=\"string\", name=\"char_inputs\")\n",
        "char_vectors = char_vectorizer(char_inputs)\n",
        "char_embeddings = char_embedding(char_vectors)\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(24))(char_embeddings)\n",
        "char_model = tf.keras.Model(inputs=char_inputs,\n",
        "                            outputs=char_bi_lstm)\n",
        "\n",
        "# 3. line numbers model\n",
        "line_inputs = layers.Input(shape=(15,) , dtype=tf.float32, name=\"line_numbers_inputs\")\n",
        "x = layers.Dense(32, activation=\"relu\")(line_inputs)\n",
        "line_number_model = tf.keras.Model(line_inputs, x)\n",
        "\n",
        "# 4. Total lines model\n",
        "total_lines_inputs = layers.Input(shape=(20,), dtype=tf.float32, name=\"total_line_inputs\")\n",
        "y = layers.Dense(32, activation=\"relu\")(total_lines_inputs)\n",
        "total_line_model = tf.keras.Model(total_lines_inputs, y)\n",
        "\n",
        "# 5. Concatenate token and char inputs(create hybrid token embedding)\n",
        "combined_embeddings = layers.Concatenate(name=\"char_token_hybrid_embedding\")([token_model.output,\n",
        "                                                                              char_model.output])\n",
        "\n",
        "z = layers.Dense(256, activation=\"relu\")(combined_embeddings)\n",
        "z = layers.Dropout(0.5)(z)\n",
        "\n",
        "# 6. Combine the positional embedding with combined token and char embedings\n",
        "tribrid_embeddings = layers.Concatenate(name=\"char_token_positional_embedding\")([line_number_model.output,\n",
        "                                                                                 total_line_model.output,\n",
        "                                                                                 z])\n",
        "\n",
        "# 7. Create output layer\n",
        "output_layer = layers.Dense(5, activation=\"softmax\", name=\"output_layer\")(tribrid_embeddings)\n",
        "\n",
        "# 8. Put together model with all kinds of inputs\n",
        "model_5 = tf.keras.Model(inputs=[line_number_model.input,\n",
        "                                 total_line_model.input,\n",
        "                                 token_model.input,\n",
        "                                 char_model.input],\n",
        "                         outputs=output_layer,\n",
        "                         name=\"model_5_tribrid_embedding_model\")"
      ],
      "metadata": {
        "id": "_lC3luC_JGXg",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:35:16.693027Z",
          "iopub.execute_input": "2023-08-05T05:35:16.693305Z",
          "iopub.status.idle": "2023-08-05T05:35:20.706691Z",
          "shell.execute_reply.started": "2023-08-05T05:35:16.693280Z",
          "shell.execute_reply": "2023-08-05T05:35:20.705671Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.summary()"
      ],
      "metadata": {
        "id": "oHtC-TJDR4GB",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:35:20.707869Z",
          "iopub.execute_input": "2023-08-05T05:35:20.708230Z",
          "iopub.status.idle": "2023-08-05T05:35:20.845389Z",
          "shell.execute_reply.started": "2023-08-05T05:35:20.708193Z",
          "shell.execute_reply": "2023-08-05T05:35:20.844362Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot model_5\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model_5, show_shapes=True )"
      ],
      "metadata": {
        "id": "ysU5hLsdQy8Y",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:35:20.847000Z",
          "iopub.execute_input": "2023-08-05T05:35:20.847611Z",
          "iopub.status.idle": "2023-08-05T05:35:21.025117Z",
          "shell.execute_reply.started": "2023-08-05T05:35:20.847574Z",
          "shell.execute_reply": "2023-08-05T05:35:21.024117Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing the model makes it much easier to understand.\n",
        "\n",
        "Essentially what we're doing is trying to encode as much information about our sequences as possible into various embeddings (the inputs to our model) so our model has the best chance to figure out what label belongs to a sequence (the outputs of our model)."
      ],
      "metadata": {
        "id": "HN2z8tHJiHOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check which layers of our model are trainable or not\n",
        "for layer in model_5.layers:\n",
        "  print(layer, layer.trainable)"
      ],
      "metadata": {
        "id": "ZvBiujDViUgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is label smoothing?\n",
        "\n",
        "For example, if our model gets too confident on a single class (e.g. its prediction probability is really high), it may get stuck on that class and not consider other classes...\n",
        "\n",
        "Really confident: `[0.0, 0.0, 1.0, 0.0, 0.0]`\n",
        "\n",
        "What label smoothing does is it assigns some of the value from the highest pred prob to other classes, in turn, hopefully improving generalization: `[0.02, 0.01, 0.96, 0.01, 0.01]`"
      ],
      "metadata": {
        "id": "Ww5Y0wEM94s4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile token, char, and positional embedding model\n",
        "model_5.compile(loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2), #helps to prevent overfitting\n",
        "                optimizer= \"adam\",\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "5E_AqdHlRocl",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:35:21.026507Z",
          "iopub.execute_input": "2023-08-05T05:35:21.026957Z",
          "iopub.status.idle": "2023-08-05T05:35:21.045416Z",
          "shell.execute_reply.started": "2023-08-05T05:35:21.026922Z",
          "shell.execute_reply": "2023-08-05T05:35:21.044503Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create tribrid embedding datasets using `tf.data`\n",
        "\n",
        "Model compiled!\n",
        "\n",
        "Again, to keep our experiments swift, let's fit on 20,000 examples for 3 epochs.\n",
        "\n",
        "This time our model requires four feature inputs:\n",
        "\n",
        " 1. Train line numbers one-hot tensor (`train_line_numbers_one_hot`)\n",
        " 2. Train total lines one-hot tensor (`train_total_lines_one_hot`)\n",
        " 3. Token-level sequences tensor (`train_sentences`)\n",
        " 4. Char-level sequences tensor (`train_chars`)\n",
        "\n",
        "We can pass these as tuples to our `tf.data.Dataset.from_tensor_slices()` method to create appropriately shaped and batched `PrefetchedDataset's.`"
      ],
      "metadata": {
        "id": "VhdTiHmRDwr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices((train_line_numbers_one_hot, train_total_lines_one_hot, train_sentences, train_chars))\n",
        "train_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot)\n",
        "train_dataset = tf.data.Dataset.zip((train_data, train_labels))\n",
        "\n",
        "val_data = tf.data.Dataset.from_tensor_slices((val_line_numbers_one_hot,val_total_lines_one_hot,val_sentences,valid_chars))\n",
        "val_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
        "val_dataset = tf.data.Dataset.zip((val_data, val_labels))\n",
        "\n",
        "test_data = tf.data.Dataset.from_tensor_slices((test_line_numbers_one_hot, test_total_lines_one_hot, test_sentences, test_chars))\n",
        "test_labels = tf.data.Dataset.from_tensor_slices(test_labels_one_hot)\n",
        "test_dataset = tf.data.Dataset.zip((test_data, test_labels))\n",
        "\n",
        "# Prefetch and batch data\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "7OT78J0UD5rg",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:35:21.046990Z",
          "iopub.execute_input": "2023-08-05T05:35:21.047382Z",
          "iopub.status.idle": "2023-08-05T05:35:23.273175Z",
          "shell.execute_reply.started": "2023-08-05T05:35:21.047348Z",
          "shell.execute_reply": "2023-08-05T05:35:23.272121Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, val_dataset"
      ],
      "metadata": {
        "id": "UDodP6TnHS4s",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:35:23.274766Z",
          "iopub.execute_input": "2023-08-05T05:35:23.275120Z",
          "iopub.status.idle": "2023-08-05T05:35:23.285835Z",
          "shell.execute_reply.started": "2023-08-05T05:35:23.275084Z",
          "shell.execute_reply": "2023-08-05T05:35:23.284835Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fitting, evaluating and making prediction with tribrid model"
      ],
      "metadata": {
        "id": "qL_cE2LiHqcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_model_5 =  model_5.fit(train_dataset,\n",
        "                               epochs=3,\n",
        "                               steps_per_epoch= int(0.1* len(train_dataset)),\n",
        "                               validation_data=(val_dataset),\n",
        "                               validation_steps=int(0.1 * len(val_dataset)))"
      ],
      "metadata": {
        "id": "URrSZycGI06U",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:35:23.287481Z",
          "iopub.execute_input": "2023-08-05T05:35:23.288161Z",
          "iopub.status.idle": "2023-08-05T05:38:35.047461Z",
          "shell.execute_reply.started": "2023-08-05T05:35:23.288122Z",
          "shell.execute_reply": "2023-08-05T05:38:35.046302Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction with the char token pos model\n",
        "model_5_pred_probs = model_5.predict(val_dataset, verbose=1)\n",
        "# Conver pred probs to pred labels\n",
        "model_5_preds = tf.argmax(model_5_pred_probs, axis=1)\n",
        "model_5_preds"
      ],
      "metadata": {
        "id": "4wsTHt-VJREc",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:38:35.049157Z",
          "iopub.execute_input": "2023-08-05T05:38:35.049668Z",
          "iopub.status.idle": "2023-08-05T05:39:35.986117Z",
          "shell.execute_reply.started": "2023-08-05T05:38:35.049629Z",
          "shell.execute_reply": "2023-08-05T05:39:35.984919Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the results of char token pos model\n",
        "model_5_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "metadata": {
        "id": "VRc9foMRK_FO",
        "execution": {
          "iopub.status.busy": "2023-08-05T05:39:35.987966Z",
          "iopub.execute_input": "2023-08-05T05:39:35.988357Z",
          "iopub.status.idle": "2023-08-05T05:39:36.012989Z",
          "shell.execute_reply.started": "2023-08-05T05:39:35.988318Z",
          "shell.execute_reply": "2023-08-05T05:39:36.011823Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare model results\n",
        "Far out, we've come a long way. From a baseline model to training a model containing three different kinds of embeddings.\n",
        "\n",
        "Now it's time to compare each model's performance against each other.\n",
        "\n",
        "We'll also be able to compare our model's to the PubMed 200k RCT: a Dataset for Sequential Sentence Classification in Medical Abstracts paper.\n",
        "\n",
        "Since all of our model results are in dictionaries, let's combine them into a pandas DataFrame to visualize them."
      ],
      "metadata": {
        "id": "Skz5a_Z3cUHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine model results into a dataframe\n",
        "all_model_results = pd.DataFrame({\"model_0_baseline\": baseline_results,\n",
        "                                 \"model_1_custom_token_embedding\": model_1_results,\n",
        "                                 \"model_2_pretrained_token_embedding\": model_2_results,\n",
        "                                 \"model_3_custom_char_embedding\": model_3_results,\n",
        "                                 \"model_4_hybrid_char_token_embedding\": model_4_results,\n",
        "                                 \"model_5_pos_char_token_embedding\": model_5_results})\n",
        "\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-05T05:52:19.331696Z",
          "iopub.execute_input": "2023-08-05T05:52:19.332085Z",
          "iopub.status.idle": "2023-08-05T05:52:19.349684Z",
          "shell.execute_reply.started": "2023-08-05T05:52:19.332052Z",
          "shell.execute_reply": "2023-08-05T05:52:19.348425Z"
        },
        "trusted": true,
        "id": "qXNgYRUAWZkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce the accuracy to same scale as other metrics\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-05T05:54:45.801305Z",
          "iopub.execute_input": "2023-08-05T05:54:45.801747Z",
          "iopub.status.idle": "2023-08-05T05:54:45.808168Z",
          "shell.execute_reply.started": "2023-08-05T05:54:45.801713Z",
          "shell.execute_reply": "2023-08-05T05:54:45.807042Z"
        },
        "trusted": true,
        "id": "AYuhhftFWZkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot and compare all model results\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10,7)).legend(bbox_to_anchor=(1.0,1.0));"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-05T05:56:57.248073Z",
          "iopub.execute_input": "2023-08-05T05:56:57.248485Z",
          "iopub.status.idle": "2023-08-05T05:56:57.688034Z",
          "shell.execute_reply.started": "2023-08-05T05:56:57.248451Z",
          "shell.execute_reply": "2023-08-05T05:56:57.687105Z"
        },
        "trusted": true,
        "id": "OfsqYBEOWZkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort model results by f1_score\n",
        "all_model_results.sort_values(\"f1\", ascending=True)[\"f1\"].plot(kind=\"bar\", figsize=(10,7))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-05T06:00:45.007090Z",
          "iopub.execute_input": "2023-08-05T06:00:45.008141Z",
          "iopub.status.idle": "2023-08-05T06:00:45.398683Z",
          "shell.execute_reply.started": "2023-08-05T06:00:45.008102Z",
          "shell.execute_reply": "2023-08-05T06:00:45.397699Z"
        },
        "trusted": true,
        "id": "yE2QOSfrWZkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save and load model\n",
        "Since we've been through a fair few experiments, it's a good idea to save our best performing model so we can reuse it without having to retrain"
      ],
      "metadata": {
        "id": "dRZT3Z99WZkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best performing model to SaveModel format (default)\n",
        "model_5.save(\"skimlit_tribrid_model\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-05T06:06:09.548053Z",
          "iopub.execute_input": "2023-08-05T06:06:09.548457Z",
          "iopub.status.idle": "2023-08-05T06:08:06.235361Z",
          "shell.execute_reply.started": "2023-08-05T06:06:09.548425Z",
          "shell.execute_reply": "2023-08-05T06:08:06.234188Z"
        },
        "trusted": true,
        "id": "QEp0DDq6WZkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pretrained model from Google Storage\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/skimlit/skimlit_tribrid_model.zip\n",
        "!mkdir skimlit_gs_model\n",
        "!unzip skimlit_tribrid_model.zip -d skimlit_gs_model"
      ],
      "metadata": {
        "id": "I1YvKtkAjd4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "model_path = \"skimlit_gs_model/skimlit_tribrid_model/\"\n",
        "\n",
        "# Load downloaded model from Google Storage\n",
        "loaded_model = tf.keras.models.load_model(model_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-05T06:08:06.478371Z",
          "iopub.execute_input": "2023-08-05T06:08:06.478738Z",
          "iopub.status.idle": "2023-08-05T06:09:04.225949Z",
          "shell.execute_reply.started": "2023-08-05T06:08:06.478701Z",
          "shell.execute_reply": "2023-08-05T06:09:04.224725Z"
        },
        "trusted": true,
        "id": "MfI1Q43kWZkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make predictions and evalaute them against the truth labels\n",
        "To make sure our model saved and loaded correctly, let's make predictions with it, evaluate them and then compare them to the prediction results we calculated earlier."
      ],
      "metadata": {
        "id": "tKEpMwm5jwGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with the loaded model on the validation set\n",
        "loaded_model_preds_probs = loaded_model.predict(val_dataset)\n",
        "loaded_preds = tf.argmax(loaded_model_preds_probs, axis=1)\n",
        "loaded_preds[:10]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-05T06:19:10.192865Z",
          "iopub.execute_input": "2023-08-05T06:19:10.193360Z",
          "iopub.status.idle": "2023-08-05T06:20:18.457632Z",
          "shell.execute_reply.started": "2023-08-05T06:19:10.193319Z",
          "shell.execute_reply": "2023-08-05T06:20:18.456214Z"
        },
        "trusted": true,
        "id": "HdGBjtu3WZkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the loaded model results\n",
        "loaded_model_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                        y_pred=loaded_preds)\n",
        "loaded_model_results"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-05T06:21:15.793688Z",
          "iopub.execute_input": "2023-08-05T06:21:15.794260Z",
          "iopub.status.idle": "2023-08-05T06:21:15.830888Z",
          "shell.execute_reply.started": "2023-08-05T06:21:15.794204Z",
          "shell.execute_reply": "2023-08-05T06:21:15.829628Z"
        },
        "trusted": true,
        "id": "9gfy3z7TWZkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_results"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-05T06:23:03.960841Z",
          "iopub.execute_input": "2023-08-05T06:23:03.961333Z",
          "iopub.status.idle": "2023-08-05T06:23:03.975911Z",
          "shell.execute_reply.started": "2023-08-05T06:23:03.961291Z",
          "shell.execute_reply": "2023-08-05T06:23:03.974729Z"
        },
        "trusted": true,
        "id": "ajCDRI1ZWZkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare loaded model results with original trained model results (should be quite close)\n",
        "np.isclose(list(model_5_results.values()), list(loaded_model_results.values()), rtol=1e-02)"
      ],
      "metadata": {
        "id": "J38VL3CZj5f7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-05T06:24:11.271331Z",
          "iopub.execute_input": "2023-08-05T06:24:11.272165Z",
          "iopub.status.idle": "2023-08-05T06:24:11.450283Z",
          "shell.execute_reply.started": "2023-08-05T06:24:11.272117Z",
          "shell.execute_reply": "2023-08-05T06:24:11.449259Z"
        },
        "trusted": true,
        "id": "4MwZFchiWZkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate model on test dataset"
      ],
      "metadata": {
        "id": "hnVxLYRGj9Xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test dataset\n",
        "test_pred_probs = loaded_model.predict(test_dataset,\n",
        "                                       verbose=1)\n",
        "test_preds = tf.argmax(test_pred_probs, axis=1)\n",
        "test_preds[:10]"
      ],
      "metadata": {
        "id": "hxGZpdhGj_eI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate loaded model test predictions\n",
        "loaded_model_test_results = calculate_results(y_true=test_labels_encoded,\n",
        "                                              y_pred=test_preds)\n",
        "loaded_model_test_results\n",
        ""
      ],
      "metadata": {
        "id": "OY1IO7h8kNxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems our best model (so far) still has some ways to go to match the performance of the results in the paper (their model gets 90.0 F1-score on the test dataset, where as ours gets ~82.1 F1-score).\n",
        "\n",
        "However, as we discussed before our model has only been trained on 20,000 out of the total ~180,000 sequences in the RCT 20k dataset. We also haven't fine-tuned our pretrained embeddings (the paper fine-tunes GloVe embeddings). So there's a couple of extensions we could try to improve our results."
      ],
      "metadata": {
        "id": "73Zsx_tikRI0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find most wrong\n",
        "One of the best ways to investigate where your model is going wrong (or potentially where your data is wrong) is to visualize the \"most wrong\" predictions.\n",
        "\n",
        "The most wrong predictions are samples where the model has made a prediction with a high probability but has gotten it wrong (the model's prediction disagreess with the ground truth label).\n",
        "\n",
        "Looking at the most wrong predictions can give us valuable information on how to improve further models or fix the labels in our data.\n",
        "\n",
        "Let's write some code to help us visualize the most wrong predictions from the test dataset.\n",
        "\n",
        "First we'll convert all of our integer-based test predictions into their string-based class names."
      ],
      "metadata": {
        "id": "aHh97UKxkR8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Get list of class names of test predictions\n",
        "test_pred_classes = [label_encoder.classes_[pred] for pred in test_preds]\n",
        "test_pred_classes"
      ],
      "metadata": {
        "id": "3tKpFW3mkXbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll enrich our test DataFame with a few values:\n",
        "\n",
        "* A \"`prediction`\" (string) column containing our model's prediction for a given sample.\n",
        "* A \"`pred_prob`\" (float) column containing the model's maximum prediction probabiliy for a given sample.\n",
        "* A \"`correct`\" (bool) column to indicate whether or not the model's prediction matches the sample's target label."
      ],
      "metadata": {
        "id": "7gQmucWUkgdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create prediction-enriched test dataframe\n",
        "test_df[\"prediction\"] = test_pred_classes # create column with test prediction class names\n",
        "test_df[\"pred_prob\"] = tf.reduce_max(test_pred_probs, axis=1).numpy() # get the maximum prediction probability\n",
        "test_df[\"correct\"] = test_df[\"prediction\"] == test_df[\"target\"] # create binary column for whether the prediction is right or not\n",
        "test_df.head(20)"
      ],
      "metadata": {
        "id": "VlXc6-EpkchE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great (or not so great)! Now we've got a subset of our model's most wrong predictions, let's write some code to visualize them."
      ],
      "metadata": {
        "id": "U6li6Rgcks1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Investigate top wrong preds\n",
        "for row in top_100_wrong[0:10].itertuples(): # adjust indexes to view different samples\n",
        "  _, target, text, line_number, total_lines, prediction, pred_prob, _ = row\n",
        "  print(f\"Target: {target}, Pred: {prediction}, Prob: {pred_prob}, Line number: {line_number}, Total lines: {total_lines}\\n\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"-----\\n\")\n",
        ""
      ],
      "metadata": {
        "id": "Ny_3RNwXktlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A next step here would be if there are a fair few samples with inconsistent labels, you could go through your training dataset, update the labels and then retrain a model. The process of using a model to help improve/investigate your dataset's labels is often referred to as **active learning**."
      ],
      "metadata": {
        "id": "xnQcpApmky6o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make example predictions\n",
        "we've made some predictions on the test dataset, now's time to really test our model out.\n",
        "\n",
        "To do so, we're going to get some data from the wild and see how our model performs.\n",
        "\n",
        "In other words, were going to find an RCT abstract from PubMed, preprocess the text so it works with our model, then pass each sequence in the wild abstract through our model to see what label it predicts.\n",
        "\n",
        "For an appropriate sample, we'll need to search PubMed for RCT's (randomized controlled trials) without abstracts which have been split up (on exploring PubMed you'll notice many of the abstracts are already preformatted into separate sections, this helps dramatically with readability).\n",
        "\n",
        "We'll use the below from https://pubmed.ncbi.nlm.nih.gov/20232240/:\n",
        "> This RCT examined the efficacy of a manualized social intervention for children with HFASDs. Participants were randomly assigned to treatment or wait-list conditions. Treatment included instruction and therapeutic activities targeting social skills, face-emotion recognition, interest expansion, and interpretation of non-literal language. A response-cost program was applied to reduce problem behaviors and foster skills acquisition. Significant treatment effects were found for five of seven primary outcome measures (parent ratings and direct child measures). Secondary measures based on staff ratings (treatment group only) corroborated gains reported by parents. High levels of parent, child and staff satisfaction were reported, along with high levels of treatment fidelity. Standardized effect size estimates were primarily in the medium and large ranges and favored the treatment group.\n",
        "\n",
        "Looking at the large chunk of text can seem quite intimidating. Now imagine you're a medical researcher trying to skim through the literature to find a study relevant to your work.\n",
        "\n",
        "Sounds like quite the challenge right?\n",
        "\n",
        "Enter SkimLit ðŸ¤“ðŸ”¥!\n",
        "\n",
        "Let's see what our best model so far (model_5) makes of the above abstract.\n",
        "\n",
        "But wait...\n",
        "\n",
        "As you might've guessed the above abstract hasn't been formatted in the same structure as the data our model has been trained on. Therefore, before we can make a prediction on it, we need to preprocess it just as we have our other sequences.\n",
        "\n",
        "More specifically, for each abstract, we'll need to:\n",
        "\n",
        " 1. Split it into sentences (lines).\n",
        " 2. Split it into characters.\n",
        " 3. Find the number of each line.\n",
        " 4. Find the total number of lines."
      ],
      "metadata": {
        "id": "ODj-gvOck0uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import json\n",
        "# Download and open example abstracts (copy and pasted from PubMed)\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/skimlit_example_abstracts.json\n",
        "\n",
        "with open(\"skimlit_example_abstracts.json\", \"r\") as f:\n",
        "  example_abstracts = json.load(f)\n",
        "\n",
        "example_abstracts"
      ],
      "metadata": {
        "id": "IcM9M8X2lWM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See what our example abstracts look like\n",
        "abstracts = pd.DataFrame(example_abstracts)\n",
        "abstracts"
      ],
      "metadata": {
        "id": "8CbJD56Ylq0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've downloaded some example abstracts, let's see how one of them goes with our trained model.\n",
        "\n",
        "First, we'll need to parse it using spaCy to turn it from a big chunk of text into sentences."
      ],
      "metadata": {
        "id": "P-95nyAslu56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sentencizer - Source: https://spacy.io/usage/linguistic-features#sbd\n",
        "from spacy.lang.en import English\n",
        "nlp = English() # setup English sentence parser\n",
        "\n",
        "# New version of spaCy\n",
        "sentencizer = nlp.add_pipe(\"sentencizer\") # create sentence splitting pipeline object\n",
        "\n",
        "# Old version of spaCy\n",
        "# sentencizer = nlp.create_pipe(\"sentencizer\") # create sentence splitting pipeline object\n",
        "# nlp.add_pipe(sentencizer) # add sentence splitting pipeline object to sentence parser\n",
        "\n",
        "# Create \"doc\" of parsed sequences, change index for a different abstract\n",
        "doc = nlp(example_abstracts[0][\"abstract\"])\n",
        "abstract_lines = [str(sent) for sent in list(doc.sents)] # return detected sentences from doc in string type (not spaCy token type)\n",
        "abstract_lines"
      ],
      "metadata": {
        "id": "ajPj_RJilvic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beautiful! It looks like spaCy has split the sentences in the abstract correctly. However, it should be noted, there may be more complex abstracts which don't get split perfectly into separate sentences (such as the example in [Baclofen promotes alcohol abstinence in alcohol dependent cirrhotic patients with hepatitis C virus (HCV) infection](https://pubmed.ncbi.nlm.nih.gov/22244707/)), in this case, more custom splitting techniques would have to be investigated.\n",
        "\n",
        "Now our abstract has been split into sentences, how about we write some code to count line numbers as well as total lines.\n",
        "\n",
        "To do so, we can leverage some of the functionality of our `preprocess_text_with_line_numbers()` function."
      ],
      "metadata": {
        "id": "3NLrZyOSl3U0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get total number of lines\n",
        "total_lines_in_sample = len(abstract_lines)\n",
        "\n",
        "# Go through each line in abstract and create a list of dictionaries containing features for each line\n",
        "sample_lines = []\n",
        "for i, line in enumerate(abstract_lines):\n",
        "  sample_dict = {}\n",
        "  sample_dict[\"text\"] = str(line)\n",
        "  sample_dict[\"line_number\"] = i\n",
        "  sample_dict[\"total_lines\"] = total_lines_in_sample - 1\n",
        "  sample_lines.append(sample_dict)\n",
        "sample_lines"
      ],
      "metadata": {
        "id": "_lZf-FfYmAj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all line_number values from sample abstract\n",
        "test_abstract_line_numbers = [line[\"line_number\"] for line in sample_lines]\n",
        "# One-hot encode to same depth as training data, so model accepts right input shape\n",
        "test_abstract_line_numbers_one_hot = tf.one_hot(test_abstract_line_numbers, depth=15)\n",
        "test_abstract_line_numbers_one_hot"
      ],
      "metadata": {
        "id": "TiRzVEu1mEYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all total_lines values from sample abstract\n",
        "test_abstract_total_lines = [line[\"total_lines\"] for line in sample_lines]\n",
        "# One-hot encode to same depth as training data, so model accepts right input shape\n",
        "test_abstract_total_lines_one_hot = tf.one_hot(test_abstract_total_lines, depth=20)\n",
        "test_abstract_total_lines_one_hot"
      ],
      "metadata": {
        "id": "MfoUVI5amFyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split abstract lines into characters\n",
        "abstract_chars = [split_chars(sentence) for sentence in abstract_lines]\n",
        "abstract_chars"
      ],
      "metadata": {
        "id": "AukxlaXimJuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alright, now we've preprocessed our wild RCT abstract into all of the same features our model was trained on, we can pass these features to our model and make sequence label predictions!"
      ],
      "metadata": {
        "id": "sgHaHM0WmMsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on sample abstract features\n",
        "%%time\n",
        "test_abstract_pred_probs = loaded_model.predict(x=(test_abstract_line_numbers_one_hot,\n",
        "                                                   test_abstract_total_lines_one_hot,\n",
        "                                                   tf.constant(abstract_lines),\n",
        "                                                   tf.constant(abstract_chars)))\n",
        "test_abstract_pred_probs"
      ],
      "metadata": {
        "id": "yR3vpCvImNiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn prediction probabilities into prediction classes\n",
        "test_abstract_preds = tf.argmax(test_abstract_pred_probs, axis=1)\n",
        "test_abstract_preds"
      ],
      "metadata": {
        "id": "jQObaXLJmQ7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got the predicted sequence label for each line in our sample abstract, let's write some code to visualize each sentence with its predicted label."
      ],
      "metadata": {
        "id": "YvPH6wjimScH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn prediction class integers into string class names\n",
        "test_abstract_pred_classes = [label_encoder.classes_[i] for i in test_abstract_preds]\n",
        "test_abstract_pred_classes"
      ],
      "metadata": {
        "id": "-vEzVxf3mUo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize abstract lines and predicted sequence labels\n",
        "for i, line in enumerate(abstract_lines):\n",
        "  print(f\"{test_abstract_pred_classes[i]}: {line}\")"
      ],
      "metadata": {
        "id": "zb-4ilVAmXJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice! Isn't that much easier to read? and how cool is that?"
      ],
      "metadata": {
        "id": "M47XxuU_mep7"
      }
    }
  ]
}